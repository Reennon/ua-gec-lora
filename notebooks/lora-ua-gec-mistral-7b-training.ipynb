{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/Reennon/ua-gec-lora.git\n!cd ua-gec-lora && pip install -r requirements.txt\n!pwd && ls -a\n# Install additional libs\n!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/transformers.git\n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git\n!pip install git+https://github.com/huggingface/trl.git@7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n!pip install ua_gec\n!pip install datasets==2.16.0\n!pip install nltk\n!pip install wandb -q -U\n# CD into the project directory\n%cd ua-gec-lora\n!git pull origin \"feature/fine-tuning-research\"\n!git status","metadata":{"_uuid":"3ccb4e12-cdd4-4d6e-a1cd-d1225a95d31d","_cell_guid":"8f20da21-c5c8-4bee-ac7b-a34823f4aa0b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T14:45:18.987077Z","iopub.execute_input":"2024-03-23T14:45:18.988241Z","iopub.status.idle":"2024-03-23T14:51:20.473531Z","shell.execute_reply.started":"2024-03-23T14:45:18.988192Z","shell.execute_reply":"2024-03-23T14:51:20.472269Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'ua-gec-lora'...\nremote: Enumerating objects: 98, done.\u001b[K\nremote: Counting objects: 100% (98/98), done.\u001b[K\nremote: Compressing objects: 100% (80/80), done.\u001b[K\nremote: Total 98 (delta 29), reused 71 (delta 13), pack-reused 0\u001b[K\nUnpacking objects: 100% (98/98), 124.83 KiB | 1.92 MiB/s, done.\nCollecting anyio==3.7.1 (from -r requirements.txt (line 1))\n  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\nCollecting dynaconf==3.2.4 (from -r requirements.txt (line 2))\n  Downloading dynaconf-3.2.4-py2.py3-none-any.whl.metadata (9.3 kB)\nCollecting huggingface-hub==0.19.4 (from -r requirements.txt (line 3))\n  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\nCollecting langchain==0.0.329 (from -r requirements.txt (line 4))\n  Downloading langchain-0.0.329-py3-none-any.whl.metadata (16 kB)\nCollecting langsmith==0.0.56 (from -r requirements.txt (line 5))\n  Downloading langsmith-0.0.56-py3-none-any.whl.metadata (10 kB)\nCollecting llama_cpp_python==0.2.13 (from -r requirements.txt (line 6))\n  Downloading llama_cpp_python-0.2.13.tar.gz (7.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting matplotlib==3.8.1 (from -r requirements.txt (line 7))\n  Downloading matplotlib-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\nCollecting numpy==1.26.1 (from -r requirements.txt (line 8))\n  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting protobuf==4.25.0 (from -r requirements.txt (line 9))\n  Downloading protobuf-4.25.0-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nCollecting pyarrow==14.0.0 (from -r requirements.txt (line 10))\n  Downloading pyarrow-14.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\nCollecting pydantic==1.10.13 (from -r requirements.txt (line 11))\n  Downloading pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (149 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dotenv==1.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (1.0.0)\nCollecting redis==5.0.1 (from -r requirements.txt (line 13))\n  Downloading redis-5.0.1-py3-none-any.whl.metadata (8.9 kB)\nCollecting safetensors==0.4.1 (from -r requirements.txt (line 14))\n  Downloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting singleton-decorator==1.0.0 (from -r requirements.txt (line 15))\n  Downloading singleton-decorator-1.0.0.tar.gz (2.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting SQLAlchemy==1.4.50 (from -r requirements.txt (line 16))\n  Downloading SQLAlchemy-1.4.50-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10.0 kB)\nCollecting streamlit==1.27.2 (from -r requirements.txt (line 17))\n  Downloading streamlit-1.27.2-py2.py3-none-any.whl.metadata (8.1 kB)\nRequirement already satisfied: tenacity==8.2.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (8.2.3)\nCollecting tokenizers==0.15.0 (from -r requirements.txt (line 19))\n  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nCollecting transformers==4.35.2 (from -r requirements.txt (line 20))\n  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio==3.7.1->-r requirements.txt (line 1)) (3.6)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio==3.7.1->-r requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio==3.7.1->-r requirements.txt (line 1)) (1.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 3)) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 3)) (2024.3.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 3)) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 3)) (4.66.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 3)) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 3)) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.19.4->-r requirements.txt (line 3)) (21.3)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.329->-r requirements.txt (line 4)) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.329->-r requirements.txt (line 4)) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.329->-r requirements.txt (line 4)) (0.6.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.329->-r requirements.txt (line 4)) (1.33)\nCollecting diskcache>=5.6.1 (from llama_cpp_python==0.2.13->-r requirements.txt (line 6))\n  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.1->-r requirements.txt (line 7)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.1->-r requirements.txt (line 7)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.1->-r requirements.txt (line 7)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.1->-r requirements.txt (line 7)) (1.4.5)\nRequirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.1->-r requirements.txt (line 7)) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.1->-r requirements.txt (line 7)) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.1->-r requirements.txt (line 7)) (2.9.0.post0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy==1.4.50->-r requirements.txt (line 16)) (3.0.3)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.27.2->-r requirements.txt (line 17)) (5.2.0)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.27.2->-r requirements.txt (line 17)) (1.7.0)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.27.2->-r requirements.txt (line 17)) (4.2.4)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.27.2->-r requirements.txt (line 17)) (8.1.7)\nRequirement already satisfied: importlib-metadata<7,>=1.4 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.27.2->-r requirements.txt (line 17)) (6.11.0)\nRequirement already satisfied: pandas<3,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.27.2->-r requirements.txt (line 17)) (2.1.4)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.27.2->-r requirements.txt (line 17)) (13.7.0)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.27.2->-r requirements.txt (line 17)) (0.10.2)\nCollecting tzlocal<6,>=1.1 (from streamlit==1.27.2->-r requirements.txt (line 17))\n  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\nCollecting validators<1,>=0.2 (from streamlit==1.27.2->-r requirements.txt (line 17))\n  Downloading validators-0.23.2-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.27.2->-r requirements.txt (line 17)) (3.1.41)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit==1.27.2->-r requirements.txt (line 17))\n  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit==1.27.2->-r requirements.txt (line 17)) (6.3.3)\nCollecting watchdog>=2.1.5 (from streamlit==1.27.2->-r requirements.txt (line 17))\n  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl.metadata (37 kB)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 20)) (2023.12.25)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.329->-r requirements.txt (line 4)) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.329->-r requirements.txt (line 4)) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.329->-r requirements.txt (line 4)) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.329->-r requirements.txt (line 4)) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.329->-r requirements.txt (line 4)) (1.3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit==1.27.2->-r requirements.txt (line 17)) (3.1.2)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit==1.27.2->-r requirements.txt (line 17)) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit==1.27.2->-r requirements.txt (line 17)) (0.12.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.329->-r requirements.txt (line 4)) (3.21.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.329->-r requirements.txt (line 4)) (0.9.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.27.2->-r requirements.txt (line 17)) (4.0.11)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7,>=1.4->streamlit==1.27.2->-r requirements.txt (line 17)) (3.17.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.329->-r requirements.txt (line 4)) (2.4)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit==1.27.2->-r requirements.txt (line 17)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit==1.27.2->-r requirements.txt (line 17)) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.8.1->-r requirements.txt (line 7)) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.19.4->-r requirements.txt (line 3)) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.19.4->-r requirements.txt (line 3)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.19.4->-r requirements.txt (line 3)) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit==1.27.2->-r requirements.txt (line 17)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit==1.27.2->-r requirements.txt (line 17)) (2.17.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.27.2->-r requirements.txt (line 17)) (5.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit==1.27.2->-r requirements.txt (line 17)) (2.1.3)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.27.2->-r requirements.txt (line 17)) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.27.2->-r requirements.txt (line 17)) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.27.2->-r requirements.txt (line 17)) (0.16.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.27.2->-r requirements.txt (line 17)) (0.1.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.329->-r requirements.txt (line 4)) (1.0.0)\nDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dynaconf-3.2.4-py2.py3-none-any.whl (223 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.9/223.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain-0.0.329-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.0.56-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading matplotlib-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading protobuf-4.25.0-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.4/294.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-14.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading redis-5.0.1-py3-none-any.whl (250 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading SQLAlchemy-1.4.50-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading streamlit-1.27.2-py2.py3-none-any.whl (7.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tzlocal-5.2-py3-none-any.whl (17 kB)\nDownloading validators-0.23.2-py3-none-any.whl (27 kB)\nDownloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: llama_cpp_python, singleton-decorator\n  Building wheel for llama_cpp_python (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for llama_cpp_python: filename=llama_cpp_python-0.2.13-cp310-cp310-manylinux_2_31_x86_64.whl size=1042004 sha256=516efe6f10ac0825859a482b13311dfec43a55b5bcfbd68c27ef97ecbd8a20b5\n  Stored in directory: /root/.cache/pip/wheels/d3/c9/89/ec02bbfa2283812eb24639ba52e929b9d773f86e4419a7da58\n  Building wheel for singleton-decorator (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for singleton-decorator: filename=singleton_decorator-1.0.0-py3-none-any.whl size=3104 sha256=13f8f0e422135b2ded320658707eb84e0e71e89531ef63b880918a4328c54846\n  Stored in directory: /root/.cache/pip/wheels/8e/70/3a/4d16f5c76159a9685f2b247e6501131b67d3c97b078bac2c1e\nSuccessfully built llama_cpp_python singleton-decorator\nInstalling collected packages: singleton-decorator, watchdog, validators, tzlocal, SQLAlchemy, safetensors, redis, pydantic, protobuf, numpy, dynaconf, diskcache, anyio, pydeck, pyarrow, llama_cpp_python, langsmith, huggingface-hub, tokenizers, matplotlib, transformers, langchain, streamlit\n  Attempting uninstall: SQLAlchemy\n    Found existing installation: SQLAlchemy 2.0.25\n    Uninstalling SQLAlchemy-2.0.25:\n      Successfully uninstalled SQLAlchemy-2.0.25\n  Attempting uninstall: safetensors\n    Found existing installation: safetensors 0.4.2\n    Uninstalling safetensors-0.4.2:\n      Successfully uninstalled safetensors-0.4.2\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.5.3\n    Uninstalling pydantic-2.5.3:\n      Successfully uninstalled pydantic-2.5.3\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: anyio\n    Found existing installation: anyio 4.2.0\n    Uninstalling anyio-4.2.0:\n      Successfully uninstalled anyio-4.2.0\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 11.0.0\n    Uninstalling pyarrow-11.0.0:\n      Successfully uninstalled pyarrow-11.0.0\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.21.4\n    Uninstalling huggingface-hub-0.21.4:\n      Successfully uninstalled huggingface-hub-0.21.4\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.5\n    Uninstalling matplotlib-3.7.5:\n      Successfully uninstalled matplotlib-3.7.5\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.38.2\n    Uninstalling transformers-4.38.2:\n      Successfully uninstalled transformers-4.38.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-nlp 0.8.2 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.1 which is incompatible.\napache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.0 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.0 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.5 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 14.0.0 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.0 which is incompatible.\ngoogle-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.0 which is incompatible.\ngoogle-cloud-pubsub 2.19.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\ngoogle-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.0 which is incompatible.\nipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.50 which is incompatible.\njupyterlab 4.1.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.0 which is incompatible.\nkfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npylibraft 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\nrmm 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.0 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\ntensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.0 which is incompatible.\ntensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.0 which is incompatible.\ntensorstore 0.1.56 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\nxarray 2024.2.0 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.1 which is incompatible.\nydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.10.13 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed SQLAlchemy-1.4.50 anyio-3.7.1 diskcache-5.6.3 dynaconf-3.2.4 huggingface-hub-0.19.4 langchain-0.0.329 langsmith-0.0.56 llama_cpp_python-0.2.13 matplotlib-3.8.1 numpy-1.26.1 protobuf-4.21.12 pyarrow-14.0.0 pydantic-1.10.13 pydeck-0.8.1b0 redis-5.0.1 safetensors-0.4.1 singleton-decorator-1.0.0 streamlit-1.27.2 tokenizers-0.15.0 transformers-4.35.2 tzlocal-5.2 validators-0.23.2 watchdog-4.0.0\n/kaggle/working\n.  ..  .virtual_documents  ua-gec-lora\nCollecting git+https://github.com/huggingface/trl.git@7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n  Cloning https://github.com/huggingface/trl.git (to revision 7630f877f91c556d9e5a3baa4b6e2894d90ff84c) to /tmp/pip-req-build-j3jbvp35\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-req-build-j3jbvp35\n  Running command git rev-parse -q --verify 'sha^7630f877f91c556d9e5a3baa4b6e2894d90ff84c'\n  Running command git fetch -q https://github.com/huggingface/trl.git 7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n  Running command git checkout -q 7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n  Resolved https://github.com/huggingface/trl.git to commit 7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.12.dev0) (2.1.2)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.12.dev0) (4.40.0.dev0)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.12.dev0) (1.26.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl==0.7.12.dev0) (0.29.0.dev0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.7.12.dev0) (2.1.0)\nCollecting tyro>=0.5.11 (from trl==0.7.12.dev0)\n  Downloading tyro-0.7.3-py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (2024.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (0.19.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (0.15.0)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (4.66.1)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.12.dev0) (0.15)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.12.dev0) (13.7.0)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.7.12.dev0)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl==0.7.12.dev0) (5.9.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.12.dev0) (14.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.12.dev0) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.12.dev0) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.12.dev0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.12.dev0) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.12.dev0) (3.9.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.12.dev0) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl==0.7.12.dev0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.12.dev0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.12.dev0) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.7.12.dev0) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.12.dev0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.12.dev0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.12.dev0) (2023.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.7.12.dev0) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.12.dev0) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.12.dev0) (1.16.0)\nDownloading tyro-0.7.3-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nBuilding wheels for collected packages: trl\n  Building wheel for trl (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for trl: filename=trl-0.7.12.dev0-py3-none-any.whl size=173433 sha256=a4e127ccf6458e6522579e0f0ec6ce7390bb2163f253aa8ba49d136cd73f0d94\n  Stored in directory: /root/.cache/pip/wheels/ad/f5/b1/f5ac48230936583c88cfde8596bc92cad4b0a4b24d0f819c06\nSuccessfully built trl\nInstalling collected packages: shtab, tyro, trl\nSuccessfully installed shtab-1.7.1 trl-0.7.12.dev0 tyro-0.7.3\nCollecting ua_gec\n  Downloading ua_gec-2.1.3-py3-none-any.whl.metadata (9.4 kB)\nDownloading ua_gec-2.1.3-py3-none-any.whl (36.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.0/36.0 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hInstalling collected packages: ua_gec\nSuccessfully installed ua_gec-2.1.3\nCollecting datasets==2.16.0\n  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (1.26.1)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (14.0.0)\nCollecting pyarrow-hotfix (from datasets==2.16.0)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.16.0)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (0.70.16)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.0)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (0.19.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets==2.16.0) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.16.0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.16.0) (2024.2.2)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.16.0)\n  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.0) (1.16.0)\nDownloading datasets-2.16.0-py3-none-any.whl (507 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, fsspec, dill, multiprocess, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.3.0\n    Uninstalling fsspec-2024.3.0:\n      Successfully uninstalled fsspec-2024.3.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.1 which is incompatible.\napache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.21.12 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 14.0.0 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ns3fs 2024.3.0 requires fsspec==2024.3.0, but you have fsspec 2023.10.0 which is incompatible.\ntensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.21.12 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.16.0 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 pyarrow-hotfix-0.6\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n/kaggle/working/ua-gec-lora\nFrom https://github.com/Reennon/ua-gec-lora\n * branch            feature/fine-tuning-research -> FETCH_HEAD\n\n*** Please tell me who you are.\n\nRun\n\n  git config --global user.email \"you@example.com\"\n  git config --global user.name \"Your Name\"\n\nto set your account's default identity.\nOmit --global to set the identity only in this repository.\n\nfatal: unable to auto-detect email address (got 'root@dca97d915230.(none)')\nOn branch master\nYour branch is up to date with 'origin/master'.\n\nnothing to commit, working tree clean\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, pipeline, Conversation, AutoTokenizer, BitsAndBytesConfig\nfrom peft import LoraConfig, TaskType, PeftModel, get_peft_model, prepare_model_for_kbit_training\nfrom src.packages.constants.error_constants import ErrorConstants\nfrom src.packages.prompts.instruction_tuning_gec_prompts import InstructionTuningGecPrompts\nfrom ua_gec import Corpus\nfrom langchain.prompts import PromptTemplate\nfrom kaggle_secrets import UserSecretsClient\nimport torch\nimport nltk\nimport wandb\n\nnltk.download('punkt')  # Download the necessary resources for sentence tokenization\n\nfrom nltk.tokenize import sent_tokenize","metadata":{"_uuid":"e0ac359a-ceb7-47da-8ef8-df68f57859b2","_cell_guid":"aafc33bc-e4b8-44ec-a258-fc80100ac0c9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T14:51:20.476043Z","iopub.execute_input":"2024-03-23T14:51:20.476419Z","iopub.status.idle":"2024-03-23T14:51:41.144211Z","shell.execute_reply.started":"2024-03-23T14:51:20.476389Z","shell.execute_reply":"2024-03-23T14:51:41.142895Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-03-23 14:51:27.947068: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-23 14:51:27.947208: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-23 14:51:28.091516: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"_uuid":"3f4d8935-2caa-45e6-a592-748524920e34","_cell_guid":"aa67b95f-2ed4-4048-8b17-41214dd6094b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T14:51:41.148875Z","iopub.execute_input":"2024-03-23T14:51:41.149360Z","iopub.status.idle":"2024-03-23T14:51:41.158401Z","shell.execute_reply.started":"2024-03-23T14:51:41.149324Z","shell.execute_reply":"2024-03-23T14:51:41.157316Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"Load HuggingFace and Weights & Biases secrets","metadata":{"_uuid":"bd81b524-99da-49bd-ab20-da2b0ee5bb5c","_cell_guid":"6516eeb5-8119-4fc2-8d24-0f2f0dcdb95b","trusted":true}},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nsecret_hf = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\nsecret_wandb = user_secrets.get_secret(\"wandb\")","metadata":{"_uuid":"53b21cd9-8ab2-4d03-bf68-76735479c684","_cell_guid":"c504d30a-6fe9-4772-80f4-6648c04a3a85","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T14:52:49.703402Z","iopub.execute_input":"2024-03-23T14:52:49.703891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Login to HuggingFace","metadata":{"_uuid":"cdc5bd5b-c106-4266-a746-844b532d8a80","_cell_guid":"d09a867a-df58-4793-8b3e-9f935af75b6a","trusted":true}},{"cell_type":"code","source":"!huggingface-cli login --token $secret_hf","metadata":{"_uuid":"f34a63a5-d6c9-4c2b-9a89-51c4a81c228c","_cell_guid":"c6a3bcb0-c992-49bd-a91c-2b46d844c2a8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.idle":"2024-03-23T14:52:51.591893Z","shell.execute_reply.started":"2024-03-23T14:52:50.001335Z","shell.execute_reply":"2024-03-23T14:52:51.590479Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Login to Weights & Biases and connect to project","metadata":{"_uuid":"af3ef21e-6e7b-41bc-93cf-58a6a5b3faaf","_cell_guid":"d4a874e4-a9c0-4083-a82f-ae2769564c85","trusted":true}},{"cell_type":"code","source":"wandb_project_name = 'UA-GEC LoRA Instruction-Tuning Mistral 7B'\n\nwandb.login(key = secret_wandb)\nrun = wandb.init(\n    project=wandb_project_name, \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T15:08:29.230533Z","iopub.execute_input":"2024-03-23T15:08:29.231285Z","iopub.status.idle":"2024-03-23T15:09:01.531559Z","shell.execute_reply.started":"2024-03-23T15:08:29.231244Z","shell.execute_reply":"2024-03-23T15:09:01.530563Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrkovalch\u001b[0m (\u001b[33mrkovalchuk\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/ua-gec-lora/wandb/run-20240323_150829-dy66j13r</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rkovalchuk/UA-GEC%20LoRA%20Instruction-Tuning%20Mistral%207B/runs/dy66j13r' target=\"_blank\">balmy-cloud-1</a></strong> to <a href='https://wandb.ai/rkovalchuk/UA-GEC%20LoRA%20Instruction-Tuning%20Mistral%207B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rkovalchuk/UA-GEC%20LoRA%20Instruction-Tuning%20Mistral%207B' target=\"_blank\">https://wandb.ai/rkovalchuk/UA-GEC%20LoRA%20Instruction-Tuning%20Mistral%207B</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rkovalchuk/UA-GEC%20LoRA%20Instruction-Tuning%20Mistral%207B/runs/dy66j13r' target=\"_blank\">https://wandb.ai/rkovalchuk/UA-GEC%20LoRA%20Instruction-Tuning%20Mistral%207B/runs/dy66j13r</a>"},"metadata":{}}]},{"cell_type":"code","source":"model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\nfine_tuned_model_name = 'rkovalchuk/mistral-7b-ua-gec'","metadata":{"_uuid":"369b322f-6627-474b-adfe-2c3cee5d5fac","_cell_guid":"ed007a40-ecd3-45c4-9c79-dc6c7763e4cd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T14:52:51.594134Z","iopub.execute_input":"2024-03-23T14:52:51.594517Z","iopub.status.idle":"2024-03-23T14:52:51.599269Z","shell.execute_reply.started":"2024-03-23T14:52:51.594484Z","shell.execute_reply":"2024-03-23T14:52:51.598351Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = prepare_model_for_kbit_training(base_model)\npeft_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,\n    inference_mode=False,\n    r=4,\n    lora_alpha=16,\n    bias=\"none\",\n    lora_dropout=0.05,  # Conventional\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n)\n\n# base_model.enable_input_require_grads()\npeft_model = get_peft_model(model, peft_config)\npeft_model.print_trainable_parameters()","metadata":{"_uuid":"9593936e-bf26-44e8-ab28-9ed6529b0867","_cell_guid":"3fc8605e-d341-4bb2-b778-2e5aa845b36a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:00:04.322085Z","iopub.execute_input":"2024-03-23T15:00:04.323119Z","iopub.status.idle":"2024-03-23T15:00:04.660956Z","shell.execute_reply.started":"2024-03-23T15:00:04.323063Z","shell.execute_reply":"2024-03-23T15:00:04.659825Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"trainable params: 5,767,168 || all params: 7,247,499,264 || trainable%: 0.07957459242040704\n","output_type":"stream"}]},{"cell_type":"code","source":"template = \"\"\"[INST] Given a text (\"ORIGINAL_TEXT\") in Ukrainian with potential errors, correct them to fulfill the GEC (Grammar Error Correction) Task, especially tailored for Mistral 7B LLM.\nConsider the provided set of error types (\"ERROR_TYPES\"):\n{error_types}\nWhen you identify an error (\"ERROR\") in the text, correct it according to the format:\n(\"ERROR\") => (\"CORRECTION\")\nThe correction should address the error without providing explicit reasoning for the change.\nThe resulting text (\"FIXED_TEXT\") should be error-free, maintaining the original information's semantics.\nFocus solely on correcting Ukrainian language errors.\nEnsure that the corrected text doesn't include original errors, additional text, comments, or parts of these instructions.\n\nORIGINAL_TEXT: {query}\nFIXED_TEXT:\n[/INST]\"\"\"\n\nit_prompt = PromptTemplate(\n    template=template,\n    input_variables=['query', 'error_types']\n)","metadata":{"_uuid":"5820b0fd-db8e-47d6-b6a4-f86af6d1729c","_cell_guid":"5cfb3154-36dd-4db6-85f7-01b9d51a77a8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:00:22.289991Z","iopub.execute_input":"2024-03-23T15:00:22.290380Z","iopub.status.idle":"2024-03-23T15:00:22.333089Z","shell.execute_reply.started":"2024-03-23T15:00:22.290355Z","shell.execute_reply":"2024-03-23T15:00:22.331644Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"max_sentences = 4","metadata":{"_uuid":"214414da-f803-43cb-b275-3200d1074a1f","_cell_guid":"2e517d0b-147e-44a6-9fe3-b040132a36dc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:00:24.349630Z","iopub.execute_input":"2024-03-23T15:00:24.350581Z","iopub.status.idle":"2024-03-23T15:00:24.354702Z","shell.execute_reply.started":"2024-03-23T15:00:24.350547Z","shell.execute_reply":"2024-03-23T15:00:24.353685Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    padding_side='left',\n    trust_remote_code=True)\n# tokenizer.pad_token = tokenizer.eos_token\n# tokenizer.add_eos_token = True","metadata":{"execution":{"iopub.status.busy":"2024-03-23T15:00:34.999459Z","iopub.execute_input":"2024-03-23T15:00:35.000455Z","iopub.status.idle":"2024-03-23T15:00:36.009835Z","shell.execute_reply.started":"2024-03-23T15:00:35.000407Z","shell.execute_reply":"2024-03-23T15:00:36.008859Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d99cc61c94c44afc9c1928eb46223544"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daa97349b296458e9383aae941b86bb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29ea602fb849423aa59b4a9a173ba80d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66964fba340d4dd79e3e6df99008f17a"}},"metadata":{}}]},{"cell_type":"code","source":"corpus = Corpus(partition=\"train\", annotation_layer=\"gec-only\")\nfor doc in corpus:\n    print(\"\\nPrompt for training:\\n\")\n    source = \"\".join(sent_tokenize(doc.source)[:max_sentences])\n    target = \"\".join(sent_tokenize(doc.target)[:max_sentences])\n    prompt = it_prompt.format_prompt(\n        query=source,\n        error_types=ErrorConstants.ERROR_TYPES\n    ).to_string()\n    prompt_with_original_text = ' '.join(prompt.split())\n    target_text = ' '.join(target.split())\n\n    # By default, the Mistral tokenizer only adds <s> (BOS token) \n    # to the prompt but not </s> (EOS token), make sure to add it at the end of your prompt.\n    instruction_tuning_template = (\n        prompt_with_original_text \n        + target_text \n        + tokenizer.eos_token\n    )\n    \n    print(instruction_tuning_template)\n    break","metadata":{"_uuid":"68489afb-eccf-4f0d-85a9-a108598573c5","_cell_guid":"ac0e5596-a728-4726-8b2b-56ffab30bd53","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:00:36.376188Z","iopub.execute_input":"2024-03-23T15:00:36.376580Z","iopub.status.idle":"2024-03-23T15:00:36.415137Z","shell.execute_reply.started":"2024-03-23T15:00:36.376552Z","shell.execute_reply":"2024-03-23T15:00:36.413943Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\nPrompt for training:\n\n[INST] Given a text (\"ORIGINAL_TEXT\") in Ukrainian with potential errors, correct them to fulfill the GEC (Grammar Error Correction) Task, especially tailored for Mistral 7B LLM. Consider the provided set of error types (\"ERROR_TYPES\"): ['Fluency', 'Grammar', 'Punctuation', 'Spelling'] When you identify an error (\"ERROR\") in the text, correct it according to the format: (\"ERROR\") => (\"CORRECTION\") The correction should address the error without providing explicit reasoning for the change. The resulting text (\"FIXED_TEXT\") should be error-free, maintaining the original information's semantics. Focus solely on correcting Ukrainian language errors. Ensure that the corrected text doesn't include original errors, additional text, comments, or parts of these instructions. ORIGINAL_TEXT: Byte for France або “Мій досвід ведення блогу у Instagram” Останні 3 місяці мого життя видалися аж занадто насиченими на події та емоції, але ось нарешті у мене з’явилося декілька вільних годин та трохи енергії щоб продовжити серію записів щодо мого досвіду блогерства.Сьогодні розповім про те як і навіщо мене занесло у Instagram.Якщо цікаво подивитися відразу на результат, то щиро прошу за цим посиланням – https://www.instagram.com/yevhenii_kanivets/ Моє бачення Instagram Колись давно я прочитав статтю, чи просто коментарій – вже не згадаю.Але йшлося там про те, що найпопулярнішою соціальною мережею стане платформа на котрій можно буде лише ділитися світлинами та ставити лайки. FIXED_TEXT: [/INST]Byte for France або “Мій досвід ведення блогу в Instagram” Останні 3 місяці мого життя видалися аж занадто насиченими на події та емоції, але ось нарешті у мене з’явилося декілька вільних годин та трохи енергії, щоб продовжити серію записів щодо мого досвіду блогерства.Сьогодні розповім про те, як і навіщо мене занесло в Instagram.Якщо цікаво подивитися відразу на результат, то щиро прошу за цим посиланням — https://www.instagram.com/yevhenii_kanivets/ Моє бачення Instagram Колись давно я прочитав статтю чи просто коментарій – уже не згадаю.Але йшлося там про те, що найпопулярнішою соціальною мережею стане платформа, на котрій можна буде лише ділитися світлинами та ставити лайки.</s>\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt_len = len(tokenizer.tokenize(instruction_tuning_template))\ntokenizer_max_len = 900\nmax_correction_addtional_tokens = 0.1\nmax_new_tokens = int(prompt_len * 1.1)\n\nprint(f\"\"\"\nPrompt len: {prompt_len}\nTokenize max length: {tokenizer_max_len}\nMax token difference because of corrections: {max_correction_addtional_tokens}\nMax new tokens len (output without input): {max_new_tokens}\n\"\"\")","metadata":{"_uuid":"77e15254-f268-4a34-bb81-762d9bc93897","_cell_guid":"aa06d60f-7d38-45c9-9f2c-4de4ae1b0cb2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:00:44.516716Z","iopub.execute_input":"2024-03-23T15:00:44.517470Z","iopub.status.idle":"2024-03-23T15:00:44.529219Z","shell.execute_reply.started":"2024-03-23T15:00:44.517433Z","shell.execute_reply":"2024-03-23T15:00:44.527967Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\nPrompt len: 771\nTokenize max length: 900\nMax token difference because of corrections: 0.1\nMax new tokens len (output without input): 848\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fix padding token for Mistral and Phi-2 models\ntokenizer.pad_token = \"[PAD]\"","metadata":{"_uuid":"7de12075-3c76-450a-a63a-bf6a1d822198","_cell_guid":"d9bc7724-3c1c-4b96-a002-62ecf50434bc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:02:36.281563Z","iopub.execute_input":"2024-03-23T15:02:36.282023Z","iopub.status.idle":"2024-03-23T15:02:36.287003Z","shell.execute_reply.started":"2024-03-23T15:02:36.281990Z","shell.execute_reply":"2024-03-23T15:02:36.285997Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model.train()\nmodel.device","metadata":{"_uuid":"0d1ed18c-43e5-4123-ad2e-19d0ecfb8c09","_cell_guid":"240fd7c0-1e41-433e-8c4f-9de15b54bd68","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:01:11.850507Z","iopub.execute_input":"2024-03-23T15:01:11.851257Z","iopub.status.idle":"2024-03-23T15:01:11.874667Z","shell.execute_reply.started":"2024-03-23T15:01:11.851221Z","shell.execute_reply":"2024-03-23T15:01:11.873503Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"torch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)","metadata":{"_uuid":"00195c69-990b-4d6a-8b24-1d9397e587e2","_cell_guid":"bdcea2a6-fa9a-4ee2-8023-0a18849e0101","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom transformers import AutoTokenizer\n\nclass UAGECDataset(Dataset):\n    def __init__(\n        self, \n        generator: object, \n        device: str,\n        prompt: object,\n        tokenizer: object,\n        max_sentences=None,\n        samples: int = None # if none will use all\n    ):\n        self.text_data =  generator#list(generator)\n        \n        if samples:\n            self.text_data = self.text_data[:samples]\n        \n        self.max_sentences = max_sentences\n        self.device = device\n        self.prompt = prompt\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.text_data)\n\n    def __getitem__(self, idx):\n        sample = self.text_data[idx]\n        \n        inputs: str = self._preprocess_text(\n            text=sample.source, \n            target_text=sample.target\n        )\n        encodings = self._tokenize_text(\n            text=inputs,\n        ).to(self.device)\n\n        return {\n            'prompt': inputs,\n            'input_ids': encodings[\"input_ids\"].squeeze(0),\n            'attention_mask': encodings[\"attention_mask\"].squeeze(0),\n        }\n    \n    def _preprocess_text(self, text: str, target_text: str) -> torch.tensor:\n        # Select top n sentences\n        text = \"\".join(sent_tokenize(text)[:self.max_sentences] if self.max_sentences else sent_tokenize(text))\n        target_text = \"\".join(sent_tokenize(target_text)[:self.max_sentences] if self.max_sentences else sent_tokenize(target_text))\n        # Add instructions (prepend prompt)\n        text = self._format_prompt(text=text)\n\n        text = self._normalize_spaces(text=text)\n        target_text = self._normalize_spaces(text=target_text)\n        # Add target response to input text\n        text += target_text\n        # Add EOS token\n        text += self.tokenizer.eos_token\n        \n        return text\n    \n    def _format_prompt(self, text: str) -> str:\n        return self.prompt.format_prompt(\n            query=text,\n            error_types=ErrorConstants.ERROR_TYPES\n        ).to_string()\n    \n    def _tokenize_text(self, text: str):\n        return self.tokenizer(\n            text, \n            max_length=tokenizer_max_len, \n            padding=\"max_length\", \n            truncation=True, \n            return_tensors=\"pt\"\n        )\n    \n    def _add_target(self, text: str, target_text: str):\n        return self.tokenizer(\n            text, \n            max_length=self.tokenizer_max_len, \n            padding=\"max_length\", \n            truncation=True, \n            return_tensors=\"pt\"\n        )\n    \n    def _normalize_spaces(self, text):\n        return ' '.join(text.split())","metadata":{"_uuid":"2219db9e-b534-40ef-a63e-3cb4e490abd0","_cell_guid":"b236c356-774d-4994-b5d2-e23d1bc7c18a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:04:09.974836Z","iopub.execute_input":"2024-03-23T15:04:09.975548Z","iopub.status.idle":"2024-03-23T15:04:09.992960Z","shell.execute_reply.started":"2024-03-23T15:04:09.975509Z","shell.execute_reply":"2024-03-23T15:04:09.991818Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_corpus = Corpus(partition=\"train\", annotation_layer=\"gec-only\")\ntrain_list = list(train_corpus)[:50]\ntest_list = list(train_corpus)[50:5]","metadata":{"_uuid":"b5cc506a-8ccb-4d71-8fa4-85b282cfbe44","_cell_guid":"b33e5e0a-b683-47ac-9ca7-ff0fceb9f6b2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:03:19.150966Z","iopub.execute_input":"2024-03-23T15:03:19.151687Z","iopub.status.idle":"2024-03-23T15:03:20.600603Z","shell.execute_reply.started":"2024-03-23T15:03:19.151655Z","shell.execute_reply":"2024-03-23T15:03:20.599504Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# train_corpus = Corpus(partition=\"train\", annotation_layer=\"gec-only\")\n# test_corpus = Corpus(partition=\"test\", annotation_layer=\"gec-only\")\ntrain_dataset, val_dataset = [UAGECDataset(\n    generator=corpus,\n    device=device,\n    prompt=it_prompt,\n    max_sentences=max_sentences,\n    tokenizer=tokenizer,\n) for corpus in [train_list, test_list]]","metadata":{"_uuid":"4ed696fe-f5df-4a11-8627-f82f0129f0e6","_cell_guid":"37e50a60-d4c3-4f88-b8ff-82abdc81cda6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:04:21.522931Z","iopub.execute_input":"2024-03-23T15:04:21.523718Z","iopub.status.idle":"2024-03-23T15:04:21.528874Z","shell.execute_reply.started":"2024-03-23T15:04:21.523685Z","shell.execute_reply":"2024-03-23T15:04:21.527863Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"_uuid":"fd746ae4-d4a0-4808-a514-5621a5c6ab39","_cell_guid":"eb6f3139-d11a-4a5d-b99f-dbf68de93400","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:04:23.449464Z","iopub.execute_input":"2024-03-23T15:04:23.449877Z","iopub.status.idle":"2024-03-23T15:04:23.505615Z","shell.execute_reply.started":"2024-03-23T15:04:23.449833Z","shell.execute_reply":"2024-03-23T15:04:23.504281Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'prompt': '[INST] Given a text (\"ORIGINAL_TEXT\") in Ukrainian with potential errors, correct them to fulfill the GEC (Grammar Error Correction) Task, especially tailored for Mistral 7B LLM. Consider the provided set of error types (\"ERROR_TYPES\"): [\\'Fluency\\', \\'Grammar\\', \\'Punctuation\\', \\'Spelling\\'] When you identify an error (\"ERROR\") in the text, correct it according to the format: (\"ERROR\") => (\"CORRECTION\") The correction should address the error without providing explicit reasoning for the change. The resulting text (\"FIXED_TEXT\") should be error-free, maintaining the original information\\'s semantics. Focus solely on correcting Ukrainian language errors. Ensure that the corrected text doesn\\'t include original errors, additional text, comments, or parts of these instructions. ORIGINAL_TEXT: Byte for France або “Мій досвід ведення блогу у Instagram” Останні 3 місяці мого життя видалися аж занадто насиченими на події та емоції, але ось нарешті у мене з’явилося декілька вільних годин та трохи енергії щоб продовжити серію записів щодо мого досвіду блогерства.Сьогодні розповім про те як і навіщо мене занесло у Instagram.Якщо цікаво подивитися відразу на результат, то щиро прошу за цим посиланням – https://www.instagram.com/yevhenii_kanivets/ Моє бачення Instagram Колись давно я прочитав статтю, чи просто коментарій – вже не згадаю.Але йшлося там про те, що найпопулярнішою соціальною мережею стане платформа на котрій можно буде лише ділитися світлинами та ставити лайки. FIXED_TEXT: [/INST]Byte for France або “Мій досвід ведення блогу в Instagram” Останні 3 місяці мого життя видалися аж занадто насиченими на події та емоції, але ось нарешті у мене з’явилося декілька вільних годин та трохи енергії, щоб продовжити серію записів щодо мого досвіду блогерства.Сьогодні розповім про те, як і навіщо мене занесло в Instagram.Якщо цікаво подивитися відразу на результат, то щиро прошу за цим посиланням — https://www.instagram.com/yevhenii_kanivets/ Моє бачення Instagram Колись давно я прочитав статтю чи просто коментарій – уже не згадаю.Але йшлося там про те, що найпопулярнішою соціальною мережею стане платформа, на котрій можна буде лише ділитися світлинами та ставити лайки.</s>',\n 'input_ids': tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     1,   733,\n         16289, 28793, 12628,   264,  2245,  4734,  1017,  2153,   775,  1086,\n         28730,  9219,  1243,   297, 23129,   753,   395,  4628,  7559, 28725,\n          4714,   706,   298, 16427,   272,   420,  8619,   325, 28777,  3212,\n          3479,  7419,  3198, 19445, 28731, 10290, 28725,  4012,  8675,  2455,\n           354, 25200,  1650, 28705, 28787, 28760, 16704, 28755, 28723, 11772,\n           272,  3857,   808,   302,  2118,  4514,  4734,  4732, 28730,  3657,\n         28735, 21021,  5936,  3188, 28718,  2090,   647,   464, 28777,  3212,\n          3479,   647,   464, 28753, 18181, 10223,   647,   464,  4941,  3572,\n          1421,  1684,   368,  9051,   396,  2118,  4734,  4732,  1243,   297,\n           272,  2245, 28725,  4714,   378,  4771,   298,   272,  5032, 28747,\n          4734,  4732,  1243,   953,  4734, 28743,  1017,   896,  5324,  1243,\n           415, 22561,  1023,  2962,   272,  2118,  1671,  7501,  9629, 24685,\n           354,   272,  2268, 28723,   415, 10503,  2245,  4734, 13286,  1906,\n         28730,  9219,  1243,  1023,   347,  2118, 28733,  3669, 28725, 17877,\n           272,  3493,  1871, 28742, 28713,  3546,   440,  1063, 28723, 24408,\n         19550,   356,  4714,   288, 23129,   753,  3842,  7559, 28723, 25217,\n           369,   272, 27840,  2245,  2368, 28742, 28707,  3024,  3493,  7559,\n         28725,  4870,  2245, 28725,  7616, 28725,   442,  5099,   302,  1167,\n         11382, 28723,  3994,  2153,   775,  1086, 28730,  9219, 28747, 20376,\n           354,  4843, 22860,   981, 28856, 28813, 28819,  2149, 28788, 28791,\n          3319,  6048,  6775,  1971,  1279,  1120,  5378,  1351, 18351, 28838,\n          2807, 12073,  2077, 28705, 28770,  7864,  1931,  3299,  4025,   803,\n          7157, 21074,  3542,  1225,   922,  1931,  1622, 28836,  1586, 20982,\n           914,   929,  2206,  1696, 15610,   929,  1051,  5777, 28869,  2937,\n          2385,  2200, 11071, 28725, 28497,   853,  1974,   929,   800, 28841,\n          8240,  1351,  1131,  8977,  1119, 28809, 20241,  1120,  1931,  3697,\n          6531,  1049,   917,   649,  7361,  5109,  8481, 28778,  2937,  3265,\n           728,  8009, 28705,   939,  1226, 10217, 28869,  8647, 28817,  2127,\n         10410,  3139,  1224, 16822, 28813, 28842,  1586, 13014,  2813,  8647,\n          2054,  4025,   803,  2149, 28788,  4093,  2454,  1279,  1120, 28810,\n          1226,  6238, 28723, 28844, 28822, 14197, 28799,  2077,  9355,  1901,\n          4093, 28803,  2127,  3882, 15143,  3213,   929,  4093,  6986,  1131,\n          8977,  1586,  1185, 12309,  1351, 18351, 28723, 28937, 28795,  6986,\n         28705,  3299,   917,  1175,  1051,  1454,  1451,  1224,  1931,  6233,\n           665,  6307,   929, 20959, 28786, 28725,  3846, 28705,  4522,   728,\n          2127, 16672,  1586, 18950, 28803,  1051,  2206, 10328,  1971, 28803,\n           764,  4449,  1508,  2849, 28723,  4138,  6806, 28723,   675, 28748,\n         28724,   828,   540,  2773, 28730,  9763,   449,  1468, 28748,  8968,\n         28893,  7460, 22948, 18351,  5779, 13279,  5005, 28791,   703,  3806,\n          2127, 27749, 28791,  3553, 28786, 28786, 28842, 28725,  9069,  2127,\n          2276,  1619, 24455,  4278, 28819,   764,   649,  2353,  2409,  1119,\n          2618,  1225, 28842, 28723, 28858,  1125, 22092, 28841,  1120,  1931,\n          2937, 28803,  2127,  3882, 28725,  8647, 15977,  1901,  4873, 22020,\n          2077,  9334, 28842,  2573,  3299,  8067, 19130,  1131,  2850,  2353,\n         28842,  3553,  1185, 12454, 28786, 22131,   929,  1619, 28786,  4278,\n         28819,  4025, 16288,  5213,  1903,  5952,  3647, 15754,   922,  1224,\n          1931,   698, 19505, 23067,  1563,  2937,  3553,  1451,  1224, 16064,\n         28819,  1107, 28723, 21467,  1906, 28730,  9219, 28747,   733, 28748,\n         16289, 28793,  8150,   354,  4843, 22860,   981, 28856, 28813, 28819,\n          2149, 28788, 28791,  3319,  6048,  6775,  1971,  1279,  1120,  5378,\n           649, 18351, 28838,  2807, 12073,  2077, 28705, 28770,  7864,  1931,\n          3299,  4025,   803,  7157, 21074,  3542,  1225,   922,  1931,  1622,\n         28836,  1586, 20982,   914,   929,  2206,  1696, 15610,   929,  1051,\n          5777, 28869,  2937,  2385,  2200, 11071, 28725, 28497,   853,  1974,\n           929,   800, 28841,  8240,  1351,  1131,  8977,  1119, 28809, 20241,\n          1120,  1931,  3697,  6531,  1049,   917,   649,  7361,  5109,  8481,\n         28778,  2937,  3265,   728,  8009, 28705,   939,  1226, 10217, 28869,\n         28725,  8647, 28817,  2127, 10410,  3139,  1224, 16822, 28813, 28842,\n          1586, 13014,  2813,  8647,  2054,  4025,   803,  2149, 28788,  4093,\n          2454,  1279,  1120, 28810,  1226,  6238, 28723, 28844, 28822, 14197,\n         28799,  2077,  9355,  1901,  4093, 28803,  2127,  3882, 28725, 15143,\n          3213,   929,  4093,  6986,  1131,  8977,  1586,  1185, 12309,   649,\n         18351, 28723, 28937, 28795,  6986, 28705,  3299,   917,  1175,  1051,\n          1454,  1451,  1224,  1931,  6233,   665,  6307,   929, 20959, 28786,\n         28725,  3846, 28705,  4522,   728,  2127, 16672,  1586, 18950, 28803,\n          1051,  2206, 10328,  1971, 28803,  1040,  4449,  1508,  2849, 28723,\n          4138,  6806, 28723,   675, 28748, 28724,   828,   540,  2773, 28730,\n          9763,   449,  1468, 28748,  8968, 28893,  7460, 22948, 18351,  5779,\n         13279,  5005, 28791,   703,  3806,  2127, 27749, 28791,  3553, 28786,\n         28786, 28842,  9069,  2127,  2276,  1619, 24455,  4278, 28819,   764,\n          1351,  2353,  2409,  1119,  2618,  1225, 28842, 28723, 28858,  1125,\n         22092, 28841,  1120,  1931,  2937, 28803,  2127,  3882, 28725,  8647,\n         15977,  1901,  4873, 22020,  2077,  9334, 28842,  2573,  3299,  8067,\n         19130,  1131,  2850,  2353, 28842,  3553,  1185, 12454, 28786, 22131,\n         28725,   929,  1619, 28786,  4278, 28819,  4025, 28836,   612,  5213,\n          1903,  5952,  3647, 15754,   922,  1224,  1931,   698, 19505, 23067,\n          1563,  2937,  3553,  1451,  1224, 16064, 28819,  1107, 28723,     2],\n        device='cuda:0'),\n 'attention_mask': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')}"},"metadata":{}}]},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\n\nfine_tuned_model_name = \"mistral-7b-ua-gec\"\n\n# # Since the model is loaded in 4bit precision, use right-side padding for tokenizer\npeft_model.config.use_cache = False\ntokenizer.padding_side = 'right'\n\ntraining_arguments = TrainingArguments(\n    output_dir=fine_tuned_model_name,\n    per_device_train_batch_size=6,\n    gradient_accumulation_steps=1,\n    gradient_checkpointing=True,\n    learning_rate=2e-4,\n    logging_steps=25,\n    num_train_epochs=5,\n    save_total_limit = 2,\n    save_strategy=\"no\",\n    load_best_model_at_end=True,\n    hub_private_repo=False,\n    report_to='wandb',\n    optim=\"paged_adamw_32bit\",\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\",\n)\npeft_model = peft_model.to(device)\ntrainer = SFTTrainer(\n    model=peft_model,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"prompt\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    max_seq_length=tokenizer_max_len,\n    packing=False,\n\n)","metadata":{"_uuid":"58d6bcc3-cbdc-411d-b62c-64f1a4a67a9f","_cell_guid":"d25b3fbc-acef-48a5-b54d-432fd35ed321","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:05:05.950337Z","iopub.execute_input":"2024-03-23T15:05:05.950751Z","iopub.status.idle":"2024-03-23T15:05:06.974263Z","shell.execute_reply.started":"2024-03-23T15:05:05.950721Z","shell.execute_reply":"2024-03-23T15:05:06.973180Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"training_arguments.device","metadata":{"_uuid":"015d8eea-02f2-4e51-9291-e792b4a6a65d","_cell_guid":"32025ae1-019d-4576-ae98-7c421f4277e2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:05:08.599718Z","iopub.execute_input":"2024-03-23T15:05:08.600631Z","iopub.status.idle":"2024-03-23T15:05:08.607671Z","shell.execute_reply.started":"2024-03-23T15:05:08.600596Z","shell.execute_reply":"2024-03-23T15:05:08.606567Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"import gc\n\ndef clear_gpu_memory():\n    torch.cuda.empty_cache()\n    print(gc.collect())","metadata":{"_uuid":"ecfb1597-1f55-434b-a3d9-9bf3e4e255ac","_cell_guid":"8ca2d82c-af6e-4f1a-b8d5-89b2153407c0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:05:12.006575Z","iopub.execute_input":"2024-03-23T15:05:12.006999Z","iopub.status.idle":"2024-03-23T15:05:12.012556Z","shell.execute_reply.started":"2024-03-23T15:05:12.006967Z","shell.execute_reply":"2024-03-23T15:05:12.011082Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"clear_gpu_memory()","metadata":{"_uuid":"432faa2c-e0a2-4503-97fa-3679b2e31eb0","_cell_guid":"0dbfced0-6dd5-449c-8e2c-3c94a703f09a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:05:13.694058Z","iopub.execute_input":"2024-03-23T15:05:13.695030Z","iopub.status.idle":"2024-03-23T15:05:14.297244Z","shell.execute_reply.started":"2024-03-23T15:05:13.694993Z","shell.execute_reply":"2024-03-23T15:05:14.296169Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"3390\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nfrom pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n\ndef wait_until_enough_gpu_memory(min_memory_available, max_retries=10, sleep_time=5):\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(torch.cuda.current_device())\n\n    for _ in range(max_retries):\n        clear_gpu_memory()\n        info = nvmlDeviceGetMemoryInfo(handle)\n        if info.free >= min_memory_available:\n            break\n        print(f\"Waiting for {min_memory_available} bytes of free GPU memory. Retrying in {sleep_time} seconds...\")\n        time.sleep(sleep_time)\n    else:\n        raise RuntimeError(f\"Failed to acquire {min_memory_available} bytes of free GPU memory after {max_retries} retries.\")\n\n# Usage example\nmin_memory_available = 2 * 1024 * 1024 * 1024  # 2GB\nclear_gpu_memory()\nwait_until_enough_gpu_memory(min_memory_available)","metadata":{"_uuid":"dd138e59-2855-4bf2-8be8-b8856f21b3e9","_cell_guid":"9be9a0cb-d339-4ac3-be14-d85368255304","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:05:16.212943Z","iopub.execute_input":"2024-03-23T15:05:16.213767Z","iopub.status.idle":"2024-03-23T15:05:16.988571Z","shell.execute_reply.started":"2024-03-23T15:05:16.213733Z","shell.execute_reply":"2024-03-23T15:05:16.987476Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"0\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"_uuid":"1405e297-b519-42f3-a308-ff5fe1f9d912","_cell_guid":"e277c972-b10c-4a86-a70d-ad9f9bb40912","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-23T15:09:10.115004Z","iopub.execute_input":"2024-03-23T15:09:10.115864Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/65 18:35 < 05:48, 0.04 it/s, Epoch 3.77/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>0.919300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"trainer.model.save_pretrained(fine_tuned_model_name)\nwandb.finish()\npeft_model.config.use_cache = True","metadata":{"_uuid":"444e4c73-a66d-41f8-a230-01d4edecf0e9","_cell_guid":"a710df00-a14e-4f85-a463-5bd5cbe2b83f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"_uuid":"763e1efb-89ca-4147-9e09-34aaf0377b20","_cell_guid":"2126f5bb-62d0-4270-a2cb-65050556a61d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}