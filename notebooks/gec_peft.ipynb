{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "!PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T15:19:42.840335Z",
     "start_time": "2024-03-02T15:19:42.712290Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: auto_gptq==0.2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: accelerate>=0.19.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (0.28.0.dev0)\r\n",
      "Requirement already satisfied: datasets in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (2.18.0)\r\n",
      "Requirement already satisfied: numpy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (1.24.4)\r\n",
      "Requirement already satisfied: rouge in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (1.0.1)\r\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (2.3.0.dev20240301)\r\n",
      "Requirement already satisfied: safetensors in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (0.4.1)\r\n",
      "Requirement already satisfied: transformers>=4.26.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (4.39.0.dev0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate>=0.19.0->auto_gptq==0.2.0) (23.1)\r\n",
      "Requirement already satisfied: psutil in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate>=0.19.0->auto_gptq==0.2.0) (5.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate>=0.19.0->auto_gptq==0.2.0) (6.0)\r\n",
      "Requirement already satisfied: huggingface-hub in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate>=0.19.0->auto_gptq==0.2.0) (0.21.3)\r\n",
      "Requirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.2.0) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.2.0) (4.8.0)\r\n",
      "Requirement already satisfied: sympy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.2.0) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.2.0) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.2.0) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.2.0) (2023.12.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers>=4.26.1->auto_gptq==0.2.0) (2023.10.3)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers>=4.26.1->auto_gptq==0.2.0) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers>=4.26.1->auto_gptq==0.2.0) (0.15.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers>=4.26.1->auto_gptq==0.2.0) (4.66.1)\r\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (14.0.0)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (1.5.3)\r\n",
      "Requirement already satisfied: xxhash in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (0.70.16)\r\n",
      "Requirement already satisfied: aiohttp in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (3.8.6)\r\n",
      "Requirement already satisfied: six in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from rouge->auto_gptq==0.2.0) (1.16.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (3.3.2)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (4.0.3)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (1.3.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers>=4.26.1->auto_gptq==0.2.0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers>=4.26.1->auto_gptq==0.2.0) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers>=4.26.1->auto_gptq==0.2.0) (2023.7.22)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->auto_gptq==0.2.0) (2.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from pandas->datasets->auto_gptq==0.2.0) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from pandas->datasets->auto_gptq==0.2.0) (2023.3.post1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from sympy->torch>=1.13.0->auto_gptq==0.2.0) (1.3.0)\r\n",
      "Collecting transformers==4.30\r\n",
      "  Obtaining dependency information for transformers==4.30 from https://files.pythonhosted.org/packages/e2/72/1af3d38e98fdcceb3876de4567ac395a66c26976e259fe2d46266e052d61/transformers-4.30.0-py3-none-any.whl.metadata\r\n",
      "  Using cached transformers-4.30.0-py3-none-any.whl.metadata (113 kB)\r\n",
      "Requirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (0.21.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (2023.10.3)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (2.31.0)\r\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30)\r\n",
      "  Obtaining dependency information for tokenizers!=0.11.3,<0.14,>=0.11.1 from https://files.pythonhosted.org/packages/70/68/0a450e4dc488031b82fcd869840c542b86aad4a07d0eca1d7e9cbb9d742e/tokenizers-0.13.3-cp310-cp310-macosx_12_0_arm64.whl.metadata\r\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-macosx_12_0_arm64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (0.4.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (4.66.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (2023.12.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (4.8.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.30) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.30) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.30) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.30) (2023.7.22)\r\n",
      "Using cached transformers-4.30.0-py3-none-any.whl (7.2 MB)\r\n",
      "Using cached tokenizers-0.13.3-cp310-cp310-macosx_12_0_arm64.whl (3.9 MB)\r\n",
      "Installing collected packages: tokenizers, transformers\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.15.2\r\n",
      "    Uninstalling tokenizers-0.15.2:\r\n",
      "      Successfully uninstalled tokenizers-0.15.2\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.39.0.dev0\r\n",
      "    Uninstalling transformers-4.39.0.dev0:\r\n",
      "      Successfully uninstalled transformers-4.39.0.dev0\r\n",
      "Successfully installed tokenizers-0.13.3 transformers-4.30.0\r\n",
      "Requirement already satisfied: optimum in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (1.17.1)\r\n",
      "Requirement already satisfied: coloredlogs in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (15.0.1)\r\n",
      "Requirement already satisfied: sympy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (1.12)\r\n",
      "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (4.30.0)\r\n",
      "Requirement already satisfied: torch>=1.11 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (2.3.0.dev20240301)\r\n",
      "Requirement already satisfied: packaging in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (23.1)\r\n",
      "Requirement already satisfied: numpy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (1.24.4)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (0.21.3)\r\n",
      "Requirement already satisfied: datasets in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (2.18.0)\r\n",
      "Requirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2023.12.1)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.66.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.8.0)\r\n",
      "Requirement already satisfied: networkx in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (2023.10.3)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.4.1)\r\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.1.99)\r\n",
      "Requirement already satisfied: protobuf<=3.20.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (3.20.0)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\r\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (14.0.0)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (1.5.3)\r\n",
      "Requirement already satisfied: xxhash in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (0.70.16)\r\n",
      "Requirement already satisfied: aiohttp in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (3.8.6)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (3.3.2)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2023.7.22)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum) (2.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.3.post1)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum) (1.16.0)\r\n",
      "Collecting git+https://github.com/huggingface/transformers.git\r\n",
      "  Cloning https://github.com/huggingface/transformers.git to /private/var/folders/gg/1kd93k4x47q5_gj92ljtjf000000gq/T/pip-req-build-n_6le_ho\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /private/var/folders/gg/1kd93k4x47q5_gj92ljtjf000000gq/T/pip-req-build-n_6le_ho\r\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 831bc25d8fdb85768402f772cf65cc3d7872b211\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (0.21.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (2023.10.3)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (2.31.0)\r\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.39.0.dev0)\r\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/01/04/45d88b8bddc09bf56ae1631721393255b75798af515c65c26389713a2072/tokenizers-0.15.2-cp310-cp310-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached tokenizers-0.15.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (0.4.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (4.66.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (2023.12.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (4.8.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (2023.7.22)\r\n",
      "Using cached tokenizers-0.15.2-cp310-cp310-macosx_11_0_arm64.whl (2.4 MB)\r\n",
      "Building wheels for collected packages: transformers\r\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for transformers: filename=transformers-4.39.0.dev0-py3-none-any.whl size=8593748 sha256=8582b3a200560e63ac486b9226a2679d96c94e716264de1024b777b6536bca5f\r\n",
      "  Stored in directory: /private/var/folders/gg/1kd93k4x47q5_gj92ljtjf000000gq/T/pip-ephem-wheel-cache-qqrixdxq/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\r\n",
      "Successfully built transformers\r\n",
      "Installing collected packages: tokenizers, transformers\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.13.3\r\n",
      "    Uninstalling tokenizers-0.13.3:\r\n",
      "      Successfully uninstalled tokenizers-0.13.3\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.30.0\r\n",
      "    Uninstalling transformers-4.30.0:\r\n",
      "      Successfully uninstalled transformers-4.30.0\r\n",
      "Successfully installed tokenizers-0.15.2 transformers-4.39.0.dev0\r\n",
      "Requirement already satisfied: accelerate in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (0.28.0.dev0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (23.1)\r\n",
      "Requirement already satisfied: psutil in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (5.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (6.0)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (2.3.0.dev20240301)\r\n",
      "Requirement already satisfied: huggingface-hub in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (0.21.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (0.4.1)\r\n",
      "Requirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\r\n",
      "Requirement already satisfied: sympy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.12.1)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install auto_gptq==0.2.0\n",
    "!pip install transformers==4.30\n",
    "!pip install --upgrade optimum\n",
    "!pip install --upgrade git+https://github.com/huggingface/transformers.git\n",
    "!pip install --upgrade accelerate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "120a237d2057493381198b92e512963e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline, Conversation, AutoTokenizer\n",
    "from src.packages.utils.parameter_server import ParameterServer\n",
    "import torch\n",
    "\n",
    "parameter_server = ParameterServer()\n",
    "\n",
    "base_model_name = \"bardsai/jaskier-7b-dpo-v6.1\"\n",
    "generator = pipeline(\"conversational\", model=base_model_name, torch_dtype=torch.half, device_map=parameter_server.settings.device, do_sample=False, top_k=0.95)\n",
    "model = generator.model\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T15:23:54.349021Z",
     "start_time": "2024-03-02T15:22:00.886790Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "LlamaTokenizerFast(name_or_path='bardsai/jaskier-7b-dpo-v6.1', vocab_size=32000, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T15:28:08.769600Z",
     "start_time": "2024-03-02T15:28:08.379540Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "['Назви найбільші міста України та коротко опиши їх. Розкажи детальніше про Львів.']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import StoppingCriteriaList, MaxLengthCriteria, MinLengthLogitsProcessor, LogitsProcessorList\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "input_ids = tokenizer(\"Назви найбільші міста України та коротко опиши їх. Розкажи детальніше про Львів\", return_tensors=\"pt\").input_ids.to(device=parameter_server.settings.device)\n",
    "\n",
    "logits_processor = LogitsProcessorList(\n",
    "    [\n",
    "        MinLengthLogitsProcessor(10, eos_token_id=model.generation_config.eos_token_id),\n",
    "    ]\n",
    ")\n",
    "stopping_criteria = StoppingCriteriaList([MaxLengthCriteria(max_length=20)])\n",
    "\n",
    "outputs = model.greedy_search(\n",
    "    input_ids, logits_processor=logits_processor, stopping_criteria=stopping_criteria\n",
    ")\n",
    "\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T15:35:42.534150Z",
     "start_time": "2024-03-02T15:35:34.373129Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `4` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Основні міста України, які заслуговують на згадування, це Київ, Харків, Херсон, Дніпро, Одеса, Львів, Харцизьк, Запоріжжя, Миколаїв, Кривий Ріг. Проте, якщо слідкувати за розмірами, населенням та історичною вагою, то Київ - столиця, найбільше місто, де зосереджена політика, культура, наука. Харків - інноваційний, науковий, промисловий центр, з багатою історією. Але тепер розкажуть детальніше про Львів. Львів - місто в західній Україні, відоме своєю багатовіковою історією, архітектурою, культурною спадщиною. Він є культурною столицею Західної України, з багатьма музеями, театрами, галере\n"
     ]
    }
   ],
   "source": [
    "conversation = Conversation()\n",
    "conversation = generator(conversation, pad_token_id=generator.tokenizer.eos_token_id)\n",
    "print(conversation.messages[-1][\"content\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T15:26:05.154018Z",
     "start_time": "2024-03-02T15:25:23.229148Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T15:05:09.608802Z",
     "start_time": "2024-03-02T15:05:09.606684Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "trainable params: 1,703,936 || all params: 7,243,436,032 || trainable%: 0.023523863432663224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    inference_mode=False,\n",
    "    r=4,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.print_trainable_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T15:05:09.763273Z",
     "start_time": "2024-03-02T15:05:09.609396Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "PeftModelForSeq2SeqLM(\n  (base_model): LoraModel(\n    (model): MistralForCausalLM(\n      (model): MistralModel(\n        (embed_tokens): Embedding(32000, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x MistralDecoderLayer(\n            (self_attn): MistralSdpaAttention(\n              (q_proj): lora.Linear(\n                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=4, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=4, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n              (v_proj): lora.Linear(\n                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=4, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=4, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n              (rotary_emb): MistralRotaryEmbedding()\n            )\n            (mlp): MistralMLP(\n              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): MistralRMSNorm()\n            (post_attention_layernorm): MistralRMSNorm()\n          )\n        )\n        (norm): MistralRMSNorm()\n      )\n      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n    )\n  )\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Source starts:---\n",
      "\n",
      "Byte for France або “Мій досвід ведення блогу у Instagram”\n",
      "Останні 3 місяці мого життя видалися аж занадто насиченими на події та емоції, але ось нарешті у мене з’явилося декілька вільних годин та трохи енергії щоб продовжити серію записів щодо мого досвіду блогерства.\n",
      "\n",
      "Сьогодні розповім про те як і навіщо мене занесло у Instagram. Якщо цікаво подивитися відразу на результат, то щиро прошу за цим посиланням – https://www.instagram.com/yevhenii_kanivets/\n",
      "\n",
      "Моє бачення Instagram\n",
      "Колись давно я прочитав статтю, чи просто коментарій – вже не згадаю. Але йшлося там про те, що найпопулярнішою соціальною мережею стане платформа на котрій можно буде лише ділитися світлинами та ставити лайки.\n",
      "\n",
      "Було це за декілька років до появи усім відомого сервісу. Як же автору вдалося передбачити майбутнє? Дуже просто!\n",
      "\n",
      "Instagram втілює глибинні бажання кожної людини:\n",
      "\n",
      "емоційне збудження від перегляду гарних фото (читання – це менш природний процес, ніж споглядання)\n",
      "нескінченне поглинання ніби-то важливої інформації про інших людей (користовуч відчуває себе у потоці)\n",
      "соціальне підтвердження того, що користувач виглядає та поводиться відповідно до тренду\n",
      "Якщо честно, то всі зазначені моменти мені не дуже близькі, тому до поїздки у Францію у мене в Instagram не було жодного фото. Але що сталося потім?\n",
      "\n",
      "Byte for France\n",
      "Французькою мовою до Франції я володів не дуже добре. Треба було якось виправляти ситуацію. Не знаю як у інших, а у мене в житті траплялось не так багато див. Знаєте, так щоб прокинувся одного ранку і володієш мовою як місцевий.\n",
      "\n",
      "Все, що я зараз вмію, давалося мені доволі важко, через щоденну працю протягом багатьох років. Але як змусити себе займатися французькою кожен день? Особливо письмом?\n",
      "\n",
      "Мені завжди було цікаво читати статті про життя закордоном. Але в них, на мій погляд, завжди не вистачало системності. Тож я вирішив започаткувати проект під назвою Byte For France – Instagram-блог, в якому б я честно та системно (кожного дня) ділився враженнями про життя у Франції французькою та російською мовами.\n",
      "\n",
      "Перші кроки\n",
      "Свій перший пост я опублікував 3-го лютого 2018 року. Це було фото валіз, котрі ми зібрали з собою до Франції. Тоді на мене були підписані лише декілька моїх друзів, але початок будо покладено.\n",
      "\n",
      "Yevhenii Kanivets's Blog\n",
      "Мій перший пост\n",
      "Я відразу ж вирішив, що буду буду писати все як є, щоб не вийшло такого, знаєте, ідеального Instagram, що показує лише приємні моменти. Я прагнув максимально точно передати свій досвід.\n",
      "\n",
      "До речі, всі ці ідеальні Instagram зламали психіку далеко не одному підлітку (та не тільки). Досі не розумію чому люди так бояться бути самими собою і створюють собі ці нудні образи “успішних людей”.\n",
      "\n",
      "Але повернемося до теми. Спочатку написання постів мені давалося дуже важко, адже я витрачав по декілька годин на їх переклад кожного дня. На щастя тем для записів було багато, залишалось тільки обирати про що розповісти.\n",
      "\n",
      "До речі поступово на мене почали підписуватися друзі та знайомі, а згодом і не знайомі люди… Як це сталося, розповім трохи далі.\n",
      "\n",
      "Прогрес та мотивація\n",
      "Якщо щось робити, то щось починає виходити. Так сталося і цього разу. Несподівано мені почала допомагати мій викладач французької мови з університету – вона корегувала кожен мій запис. Помилок було дуже багато, але кожного разу їх було все менше і це не могло не радувати.\n",
      "\n",
      "Поступово мені дуже сподобалося ділитися цікавою інформацією, що могла стати у нагоді іншим людям. Мені здається, що я навіть почав жити цікавіше, щоб було про що розповісти.\n",
      "\n",
      "Ми відвідували багато музеїв, парків, подорожували по іншим містам та країнам. Я навіть писав про свої співбесіди та роботу, власні думки.\n",
      "\n",
      "Звідки беруться підписники?\n",
      "Instagram створено таким чином, щоб отримати підписників органічним шляхом було максимально важко. У головній стрічці кожен користувач бачить лише тих на кого вже підписаний. У пошуку користувач переглядає контент, не звертаючи особливої уваги на його автора.\n",
      "\n",
      "Таким чином кожен користувач має привести підписників з іншого джерела (реальних знайомих, наприклад) або ж придбати рекламу в Instagram, щоб влізти зі своїм контентом у стрічку незнайомців.\n",
      "\n",
      "Третій спосіб, на котрий витрачають час звичайні користувачі – лайки та підписки на інших користувачів у надії на те, що ті підпишуться у відповідь. Зазвичай кількість підписок / підписників у таких користувачів майже однакова.\n",
      "\n",
      "Є ще четвертий спосіб, але він вже для зовсім зневірених людей – придбання підписок та лайків. Є (чи принаймні були) цілі мережі фейкових аккаунтів, що за невелику винагороду підпишуться, пролайкають та навіть прокоментують ваші пости.\n",
      "\n",
      "Тільки задумайтесь, що люди готові витрачати власні кошти та брехати тисячам інших людей, лиша заради того, щоб виглядати краще у очах тих же самих людей. Але проблема мабуть не в Instagram, чи не так?\n",
      "\n",
      "Розумне чи хитре рішення?\n",
      "Як і кожному Instagram-блогеру, мені здавалося, що мій контент має побачити більше людей. Тому після того як перша хвиля підписників закінчилася (знайомі та друзі із реального життя), я вирішив, що потрібно збільшити охоплення іншим шляхом.\n",
      "\n",
      "Саморекламу можно було організувати за рахунок лайків іншим користувачам, що доволі просто було автоматизувати за допомогою цього проекту – https://github.com/instabot-py/instabot.py.\n",
      "\n",
      "Yevhenii Kanivets's Blog\n",
      "Мій IoT набір, який я пізніше використовував для Instagram\n",
      "Але ставити лайки рандомним користувачам було не дуже еффективно, тож я написав пошук в ширину і зібрав список підписників моїх підписників, що ймовірно могли про мене чути.\n",
      "\n",
      "У результаті мій скрипт пропрацював близько 2 місяців запущений на Raspberry Pi вдень та вночі, збільшивши кількість моїх підписніків до 1000. Потім мені стало нудно і я перестав займатися цією “дуже важливою” справою.\n",
      "\n",
      "Результати\n",
      "Я успішно завершив свій проект через 256 днів після його початку. Рівень моєї французької значно виріс. Крім того я дізнався та розповів про багато цікавих речей та подій. Нарешті мені вдалося розібратися з тим що так Instagram і навіщо він потрібен.\n",
      "\n",
      "Нажаль Instagram перетворився у місце маніфестації свого “успіху” та марнування власного часу для більшості користувачів. Але не думаю, що проблема у самому ресурсі – він просто дав людям те, чого вони хотіли.\n",
      "\n",
      "Мені дуже подобається освітній контент, що спрямовано на розвиток людини – звіти про івенти, подорожі, книги та фільми, лайфхаки. Загалом все, що несе у собі цінність для когось окрім самолюбства автора…\n",
      "\n",
      "\n",
      "---Source ends:---\n",
      "\n",
      "\n",
      "---Target starts:---\n",
      "\n",
      "Byte for France або “Мій досвід ведення блогу в Instagram”\n",
      "Останні 3 місяці мого життя видалися аж занадто насиченими на події та емоції, але ось нарешті у мене з’явилося декілька вільних годин та трохи енергії, щоб продовжити серію записів щодо мого досвіду блогерства.\n",
      "\n",
      "Сьогодні розповім про те, як і навіщо мене занесло в Instagram. Якщо цікаво подивитися відразу на результат, то щиро прошу за цим посиланням — https://www.instagram.com/yevhenii_kanivets/\n",
      "\n",
      "Моє бачення Instagram\n",
      "Колись давно я прочитав статтю чи просто коментарій – уже не згадаю. Але йшлося там про те, що найпопулярнішою соціальною мережею стане платформа, на котрій можна буде лише ділитися світлинами та ставити лайки.\n",
      "\n",
      "Було це за декілька років до появи всім відомого сервісу. Як же авторові вдалося передбачити майбутнє? Дуже просто!\n",
      "\n",
      "Instagram втілює глибинні бажання кожної людини:\n",
      "\n",
      "емоційне збудження від перегляду гарних фото (читання — це менш природний процес, аніж споглядання);\n",
      "нескінченне поглинання нібито важливої інформації про інших людей (користувач відчуває себе у потоці);\n",
      "соціальне підтвердження того, що користувач виглядає та поводиться відповідно до тренду;\n",
      "Якщо чесно, то всі зазначені моменти мені не дуже близькі, тому до поїздки у Францію у мене в Instagram не було жодного фото. Але що сталося потім?\n",
      "\n",
      "Byte for France\n",
      "Французькою мовою до Франції я володів не дуже добре. Треба було якось виправляти ситуацію. Не знаю, як у інших, а у мене в житті траплялось не так багато див. Знаєте, так щоб прокинувся одного ранку і володієш мовою як місцевий.\n",
      "\n",
      "Все, що я зараз вмію, давалося мені доволі важко, через щоденну працю протягом багатьох років. Але як змусити себе займатися французькою кожен день? Особливо письмом?\n",
      "\n",
      "Мені завжди було цікаво читати статті про життя за кордоном. Але їм, на мій погляд, завжди не вистачало системності. Тож я вирішив започаткувати проєкт під назвою Byte For France — Instagram-блог, в якому б я чесно та системно (кожного дня) ділився враженнями про життя у Франції французькою та російською мовами.\n",
      "\n",
      "Перші кроки\n",
      "Свій перший пост я опублікував 3-го лютого 2018 року. Це було фото валіз, котрі ми зібрали з собою до Франції. Тоді на мене були підписані лише декілька моїх друзів, але початок було покладено.\n",
      "\n",
      "Yevhenii Kanivets's Blog\n",
      "Мій перший пост\n",
      "Я відразу ж вирішив, що описуватиму все як є, щоб не вийшло такого, знаєте, ідеального Instagram, що показує лише приємні моменти. Я прагнув максимально точно передати свій досвід.\n",
      "\n",
      "До речі, всі ці ідеальні Instagram зламали психіку далеко не одному підлітку (та не тільки). Досі не розумію, чому люди так бояться бути самими собою і створюють собі ці нудні образи “успішних людей”.\n",
      "\n",
      "Але повернімося до теми. Спочатку написання постів мені давалося дуже важко, адже я витрачав по декілька годин на їхній переклад кожного дня. На щастя, тем для записів було багато, залишалось тільки обирати, про що розповісти.\n",
      "\n",
      "До речі, поступово на мене почали підписуватися друзі та знайомі, а згодом і незнайомі люди… Як це сталося, розповім трохи далі.\n",
      "\n",
      "Прогрес та мотивація\n",
      "Якщо щось робити, то щось починає виходити. Так сталося і цього разу. Несподівано мені почала допомагати моя викладачка французької мови з університету — вона корегувала кожен мій запис. Помилок було дуже багато, але кожного разу їх було все менше і це не могло не радувати.\n",
      "\n",
      "Поступово мені дуже сподобалося ділитися цікавою інформацією, що могла стати у нагоді іншим людям. Мені здається, що я навіть почав жити цікавіше, щоб було про що розповісти.\n",
      "\n",
      "Ми відвідували багато музеїв, парків, подорожували іншими містами та країнами. Я навіть писав про свої співбесіди та роботу, власні думки.\n",
      "\n",
      "Звідки беруться підписники?\n",
      "Instagram створено таким чином, щоб отримати підписників органічним шляхом було максимально важко. У головній стрічці кожен користувач бачить лише тих, на кого вже підписаний. У пошуку користувач переглядає контент, не звертаючи особливої уваги на його автора.\n",
      "\n",
      "Таким чином кожен користувач має привести підписників з іншого джерела (реальних знайомих, наприклад) або ж придбати рекламу в Instagram, щоб влізти зі своїм контентом у стрічку незнайомців.\n",
      "\n",
      "Третій спосіб, на котрий витрачають час звичайні користувачі, – лайки та підписки за іншими користувачами у надії на те, що ті підпишуться у відповідь. Зазвичай кількість підписок / підписників у таких користувачів майже однакова.\n",
      "\n",
      "Є ще четвертий спосіб, але він уже для зовсім зневірених людей — придбання підписок та лайків. Є (чи принаймні були) цілі мережі фейкових акаунтів, що за невелику винагороду за вами підпишуться, пролайкають і навіть прокоментують ваші пости.\n",
      "\n",
      "Тільки задумайтесь, що люди готові витрачати власні кошти та брехати тисячам інших людей, лише заради того, щоб виглядати кращими, у очах тих же самих людей. Але проблема мабуть не в Instagram, чи не так?\n",
      "\n",
      "Розумне чи хитре рішення?\n",
      "Як і кожному Instagram-блогеру, мені здавалося, що мій контент має побачити більше людей. Тому після того як перша хвиля підписників закінчилася (знайомі та друзі із реального життя), я вирішив, що потрібно збільшити охоплення іншим шляхом.\n",
      "\n",
      "Саморекламу можна було організувати за рахунок лайків іншим користувачам, що доволі просто було автоматизувати за допомогою цього проекту — https://github.com/instabot-py/instabot.py.\n",
      "\n",
      "Yevhenii Kanivets's Blog\n",
      "Мій IoT набір, який я пізніше використовував для Instagram.\n",
      "Але ставити лайки рандомним користувачам було не дуже ефективно, тож я написав пошук у ширину і зібрав список підписників моїх підписників, що ймовірно могли про мене чути.\n",
      "\n",
      "У результаті мій скрипт, запущений на Raspberry Pi, пропрацював близько 2 місяців  удень та вночі, збільшивши кількість моїх підписніків до 1000. Потім мені стало нудно, і я перестав займатися цією “дуже важливою” справою.\n",
      "\n",
      "Результати\n",
      "Я успішно завершив свій проект через 256 днів після його початку. Рівень моєї французької значно виріс. Крім того, я дізнався і розповів про багато цікавих речей та подій. Нарешті мені вдалося розібратися з тим, що таке Instagram і навіщо він потрібен.\n",
      "\n",
      "На жаль, Instagram перетворився на місце маніфестації свого “успіху” та марнування власного часу для більшості користувачів. Але не думаю, що проблема у самому ресурсі — він просто дав людям те, чого вони хотіли.\n",
      "\n",
      "Мені дуже подобається освітній контент, який спрямовано на розвиток людини — звіти про івенти, подорожі, книги та фільми, лайфхаки. Загалом усе, що несе у собі цінність для когось, окрім самолюбства автора…\n",
      "\n",
      "\n",
      "---Target ends---\n",
      "\n",
      "\n",
      "---Annotation starts:---\n",
      "\n",
      "Byte for France або “Мій досвід ведення блогу {у=>в:::error_type=Spelling} Instagram”\n",
      "Останні 3 місяці мого життя видалися аж занадто насиченими на події та емоції, але ось нарешті у мене з’явилося декілька вільних годин та трохи енергії{=>,:::error_type=Punctuation} щоб продовжити серію записів щодо мого досвіду блогерства.\n",
      "\n",
      "Сьогодні розповім про те{=>,:::error_type=Punctuation} як і навіщо мене занесло {у=>в:::error_type=Spelling} Instagram. Якщо цікаво подивитися відразу на результат, то щиро прошу за цим посиланням {–=>—:::error_type=Punctuation} https://www.instagram.com/yevhenii_kanivets/\n",
      "\n",
      "Моє бачення Instagram\n",
      "Колись давно я прочитав статтю{,=>:::error_type=Punctuation} чи просто коментарій – {вже=>уже:::error_type=Spelling} не згадаю. Але йшлося там про те, що найпопулярнішою соціальною мережею стане платформа{=>,:::error_type=Punctuation} на котрій {можно=>можна:::error_type=Spelling} буде лише ділитися світлинами та ставити лайки.\n",
      "\n",
      "Було це за декілька років до появи {усім=>всім:::error_type=Spelling} відомого сервісу. Як же {автору=>авторові:::error_type=G/Case} вдалося передбачити майбутнє? Дуже просто!\n",
      "\n",
      "Instagram втілює глибинні бажання кожної людини:\n",
      "\n",
      "емоційне збудження від перегляду гарних фото (читання {–=>—:::error_type=Punctuation} це менш природний процес, {ніж=>аніж:::error_type=Spelling} споглядання){=>;:::error_type=Punctuation}\n",
      "нескінченне поглинання {ніби-то=>нібито:::error_type=Spelling} важливої інформації про інших людей ({користовуч=>користувач:::error_type=Spelling} відчуває себе у потоці){=>;:::error_type=Punctuation}\n",
      "соціальне підтвердження того, що користувач виглядає та поводиться відповідно до тренду{=>;:::error_type=Punctuation}\n",
      "Якщо {честно=>чесно:::error_type=Spelling}, то всі зазначені моменти мені не дуже близькі, тому до поїздки у Францію у мене в Instagram не було жодного фото. Але що сталося потім?\n",
      "\n",
      "Byte for France\n",
      "Французькою мовою до Франції я володів не дуже добре. Треба було якось виправляти ситуацію. Не знаю{=>,:::error_type=Punctuation} як у інших, а у мене в житті траплялось не так багато див. Знаєте, так щоб прокинувся одного ранку і володієш мовою як місцевий.\n",
      "\n",
      "Все, що я зараз вмію, давалося мені доволі важко, через щоденну працю протягом багатьох років. Але як змусити себе займатися французькою кожен день? Особливо письмом?\n",
      "\n",
      "Мені завжди було цікаво читати статті про життя {закордоном=>за кордоном:::error_type=Spelling}. Але {в них=>їм:::error_type=G/Case}, на мій погляд, завжди не вистачало системності. Тож я вирішив започаткувати {проект=>проєкт:::error_type=Spelling} під назвою Byte For France {–=>—:::error_type=Punctuation} Instagram-блог, в якому б я {честно=>чесно:::error_type=Spelling} та системно (кожного дня) ділився враженнями про життя у Франції французькою та російською мовами.\n",
      "\n",
      "Перші кроки\n",
      "Свій перший пост я опублікував 3-го лютого 2018 року. Це було фото валіз, котрі ми зібрали з собою до Франції. Тоді на мене були підписані лише декілька моїх друзів, але початок {будо=>було:::error_type=Spelling} покладено.\n",
      "\n",
      "Yevhenii Kanivets's Blog\n",
      "Мій перший пост\n",
      "Я відразу ж вирішив, що {буду =>:::error_type=Spelling}{буду писати=>описуватиму:::error_type=G/VerbAForm} все як є, щоб не вийшло такого, знаєте, ідеального Instagram, що показує лише приємні моменти. Я прагнув максимально точно передати свій досвід.\n",
      "\n",
      "До речі, всі ці ідеальні Instagram зламали психіку далеко не одному підлітку (та не тільки). Досі не розумію{=>,:::error_type=Punctuation} чому люди так бояться бути самими собою і створюють собі ці нудні образи “успішних людей”.\n",
      "\n",
      "Але {повернемося=>повернімося:::error_type=G/VerbVoice} до теми. Спочатку написання постів мені давалося дуже важко, адже я витрачав по декілька годин на {їх=>їхній:::error_type=G/Case} переклад кожного дня. На щастя{=>,:::error_type=Punctuation} тем для записів було багато, залишалось тільки обирати{=>,:::error_type=Punctuation} про що розповісти.\n",
      "\n",
      "До речі{=>,:::error_type=Punctuation} поступово на мене почали підписуватися друзі та знайомі, а згодом і {не знайомі=>незнайомі:::error_type=Spelling} люди… Як це сталося, розповім трохи далі.\n",
      "\n",
      "Прогрес та мотивація\n",
      "Якщо щось робити, то щось починає виходити. Так сталося і цього разу. Несподівано мені почала допомагати {мій викладач=>моя викладачка:::error_type=G/Gender} французької мови з університету {–=>—:::error_type=Punctuation} вона корегувала кожен мій запис. Помилок було дуже багато, але кожного разу їх було все менше і це не могло не радувати.\n",
      "\n",
      "Поступово мені дуже сподобалося ділитися цікавою інформацією, що могла стати у нагоді іншим людям. Мені здається, що я навіть почав жити цікавіше, щоб було про що розповісти.\n",
      "\n",
      "Ми відвідували багато музеїв, парків, подорожували {по іншим містам=>іншими містами:::error_type=G/Case} та {країнам=>країнами:::error_type=G/Case}. Я навіть писав про свої співбесіди та роботу, власні думки.\n",
      "\n",
      "Звідки беруться підписники?\n",
      "Instagram створено таким чином, щоб отримати підписників органічним шляхом було максимально важко. У головній стрічці кожен користувач бачить лише тих{=>,:::error_type=Punctuation} на кого вже підписаний. У пошуку користувач переглядає контент, не звертаючи особливої уваги на його автора.\n",
      "\n",
      "Таким чином кожен користувач має привести підписників з іншого джерела (реальних знайомих, наприклад) або ж придбати рекламу в Instagram, щоб влізти зі своїм контентом у стрічку незнайомців.\n",
      "\n",
      "Третій спосіб, на котрий витрачають час звичайні користувачі{=>,:::error_type=Punctuation} – лайки та підписки {на інших користувачів=>за іншими користувачами:::error_type=G/Case} у надії на те, що ті підпишуться у відповідь. Зазвичай кількість підписок / підписників у таких користувачів майже однакова.\n",
      "\n",
      "Є ще четвертий спосіб, але він {вже=>уже:::error_type=Spelling} для зовсім зневірених людей {–=>—:::error_type=Punctuation} придбання підписок та лайків. Є (чи принаймні були) цілі мережі фейкових {аккаунтів=>акаунтів:::error_type=Spelling}, що за невелику винагороду{=> за вами:::error_type=G/UngrammaticalStructure} підпишуться, пролайкають {та=>і:::error_type=Spelling} навіть прокоментують ваші пости.\n",
      "\n",
      "Тільки задумайтесь, що люди готові витрачати власні кошти та брехати тисячам інших людей, {лиша=>лише:::error_type=Spelling} заради того, щоб виглядати {краще=>кращими:::error_type=G/Case}{=>,:::error_type=Punctuation} у очах тих же самих людей. Але проблема мабуть не в Instagram, чи не так?\n",
      "\n",
      "Розумне чи хитре рішення?\n",
      "Як і кожному Instagram-блогеру, мені здавалося, що мій контент має побачити більше людей. Тому після того як перша хвиля підписників закінчилася (знайомі та друзі із реального життя), я вирішив, що потрібно збільшити охоплення іншим шляхом.\n",
      "\n",
      "Саморекламу {можно=>можна:::error_type=Spelling} було організувати за рахунок лайків іншим користувачам, що доволі просто було автоматизувати за допомогою цього проекту {–=>—:::error_type=Punctuation} https://github.com/instabot-py/instabot.py.\n",
      "\n",
      "Yevhenii Kanivets's Blog\n",
      "Мій IoT набір, який я пізніше використовував для Instagram{=>.:::error_type=Punctuation}\n",
      "Але ставити лайки рандомним користувачам було не дуже {еффективно=>ефективно:::error_type=Spelling}, тож я написав пошук {в=>у:::error_type=Spelling} ширину і зібрав список підписників моїх підписників, що ймовірно могли про мене чути.\n",
      "\n",
      "У результаті мій скрипт{=>, запущений на Raspberry Pi,:::error_type=G/UngrammaticalStructure} пропрацював близько 2 місяців {запущений на Raspberry Pi=>:::error_type=G/UngrammaticalStructure} {вдень=>удень:::error_type=Spelling} та вночі, збільшивши кількість моїх підписніків до 1000. Потім мені стало нудно{=>,:::error_type=Punctuation} і я перестав займатися цією “дуже важливою” справою.\n",
      "\n",
      "Результати\n",
      "Я успішно завершив свій проект через 256 днів після його початку. Рівень моєї французької значно виріс. Крім того{=>,:::error_type=Punctuation} я дізнався {та=>і:::error_type=Spelling} розповів про багато цікавих речей та подій. Нарешті мені вдалося розібратися з тим{=>,:::error_type=Punctuation} що {так=>таке:::error_type=Spelling} Instagram і навіщо він потрібен.\n",
      "\n",
      "{Нажаль=>На жаль:::error_type=Spelling}{=>,:::error_type=Punctuation} Instagram перетворився {у=>на:::error_type=G/Prep} місце маніфестації свого “успіху” та марнування власного часу для більшості користувачів. Але не думаю, що проблема у самому ресурсі {–=>—:::error_type=Punctuation} він просто дав людям те, чого вони хотіли.\n",
      "\n",
      "Мені дуже подобається освітній контент, {що=>який:::error_type=G/Conjunction} спрямовано на розвиток людини {–=>—:::error_type=Punctuation} звіти про івенти, подорожі, книги та фільми, лайфхаки. Загалом {все=>усе:::error_type=Spelling}, що несе у собі цінність для когось{=>,:::error_type=Punctuation} окрім самолюбства автора…\n",
      "\n",
      "Харківська\n",
      "\n",
      "---Annotation ends\n",
      "\n",
      "---Prompt starts\n",
      "text='Given (\"SOURCE\") text, correct errors if present, fulfilling GEC (Grammar Error Correction) Task for Ukrainian Language.\\nUse following set of errors (\"ERROR_TYPES\"):\\n[\\'Fluency\\', \\'Grammar\\', \\'Punctuation\\', \\'Spelling\\']\\nIf you would detect error (\"ERROR\"), generate correction (\"CORRECTION\") following the structure and specifying error type (\"ERROR_TYPE\"):\\n{(\"ERROR\")=>(\"CORRECTION\"):::(\"ERROR_TYPE\")}\\nOtherwise keep original text.\\n\\nSOURCE: Byte for France або “Мій досвід ведення блогу у Instagram”\\nОстанні 3 місяці мого життя видалися аж занадто насиченими на події та емоції, але ось нарешті у мене з’явилося декілька вільних годин та трохи енергії щоб продовжити серію записів щодо мого досвіду блогерства.\\n\\nСьогодні розповім про те як і навіщо мене занесло у Instagram. Якщо цікаво подивитися відразу на результат, то щиро прошу за цим посиланням – https://www.instagram.com/yevhenii_kanivets/\\n\\nМоє бачення Instagram\\nКолись давно я прочитав статтю, чи просто коментарій – вже не згадаю. Але йшлося там про те, що найпопулярнішою соціальною мережею стане платформа на котрій можно буде лише ділитися світлинами та ставити лайки.\\n\\nБуло це за декілька років до появи усім відомого сервісу. Як же автору вдалося передбачити майбутнє? Дуже просто!\\n\\nInstagram втілює глибинні бажання кожної людини:\\n\\nемоційне збудження від перегляду гарних фото (читання – це менш природний процес, ніж споглядання)\\nнескінченне поглинання ніби-то важливої інформації про інших людей (користовуч відчуває себе у потоці)\\nсоціальне підтвердження того, що користувач виглядає та поводиться відповідно до тренду\\nЯкщо честно, то всі зазначені моменти мені не дуже близькі, тому до поїздки у Францію у мене в Instagram не було жодного фото. Але що сталося потім?\\n\\nByte for France\\nФранцузькою мовою до Франції я володів не дуже добре. Треба було якось виправляти ситуацію. Не знаю як у інших, а у мене в житті траплялось не так багато див. Знаєте, так щоб прокинувся одного ранку і володієш мовою як місцевий.\\n\\nВсе, що я зараз вмію, давалося мені доволі важко, через щоденну працю протягом багатьох років. Але як змусити себе займатися французькою кожен день? Особливо письмом?\\n\\nМені завжди було цікаво читати статті про життя закордоном. Але в них, на мій погляд, завжди не вистачало системності. Тож я вирішив започаткувати проект під назвою Byte For France – Instagram-блог, в якому б я честно та системно (кожного дня) ділився враженнями про життя у Франції французькою та російською мовами.\\n\\nПерші кроки\\nСвій перший пост я опублікував 3-го лютого 2018 року. Це було фото валіз, котрі ми зібрали з собою до Франції. Тоді на мене були підписані лише декілька моїх друзів, але початок будо покладено.\\n\\nYevhenii Kanivets\\'s Blog\\nМій перший пост\\nЯ відразу ж вирішив, що буду буду писати все як є, щоб не вийшло такого, знаєте, ідеального Instagram, що показує лише приємні моменти. Я прагнув максимально точно передати свій досвід.\\n\\nДо речі, всі ці ідеальні Instagram зламали психіку далеко не одному підлітку (та не тільки). Досі не розумію чому люди так бояться бути самими собою і створюють собі ці нудні образи “успішних людей”.\\n\\nАле повернемося до теми. Спочатку написання постів мені давалося дуже важко, адже я витрачав по декілька годин на їх переклад кожного дня. На щастя тем для записів було багато, залишалось тільки обирати про що розповісти.\\n\\nДо речі поступово на мене почали підписуватися друзі та знайомі, а згодом і не знайомі люди… Як це сталося, розповім трохи далі.\\n\\nПрогрес та мотивація\\nЯкщо щось робити, то щось починає виходити. Так сталося і цього разу. Несподівано мені почала допомагати мій викладач французької мови з університету – вона корегувала кожен мій запис. Помилок було дуже багато, але кожного разу їх було все менше і це не могло не радувати.\\n\\nПоступово мені дуже сподобалося ділитися цікавою інформацією, що могла стати у нагоді іншим людям. Мені здається, що я навіть почав жити цікавіше, щоб було про що розповісти.\\n\\nМи відвідували багато музеїв, парків, подорожували по іншим містам та країнам. Я навіть писав про свої співбесіди та роботу, власні думки.\\n\\nЗвідки беруться підписники?\\nInstagram створено таким чином, щоб отримати підписників органічним шляхом було максимально важко. У головній стрічці кожен користувач бачить лише тих на кого вже підписаний. У пошуку користувач переглядає контент, не звертаючи особливої уваги на його автора.\\n\\nТаким чином кожен користувач має привести підписників з іншого джерела (реальних знайомих, наприклад) або ж придбати рекламу в Instagram, щоб влізти зі своїм контентом у стрічку незнайомців.\\n\\nТретій спосіб, на котрий витрачають час звичайні користувачі – лайки та підписки на інших користувачів у надії на те, що ті підпишуться у відповідь. Зазвичай кількість підписок / підписників у таких користувачів майже однакова.\\n\\nЄ ще четвертий спосіб, але він вже для зовсім зневірених людей – придбання підписок та лайків. Є (чи принаймні були) цілі мережі фейкових аккаунтів, що за невелику винагороду підпишуться, пролайкають та навіть прокоментують ваші пости.\\n\\nТільки задумайтесь, що люди готові витрачати власні кошти та брехати тисячам інших людей, лиша заради того, щоб виглядати краще у очах тих же самих людей. Але проблема мабуть не в Instagram, чи не так?\\n\\nРозумне чи хитре рішення?\\nЯк і кожному Instagram-блогеру, мені здавалося, що мій контент має побачити більше людей. Тому після того як перша хвиля підписників закінчилася (знайомі та друзі із реального життя), я вирішив, що потрібно збільшити охоплення іншим шляхом.\\n\\nСаморекламу можно було організувати за рахунок лайків іншим користувачам, що доволі просто було автоматизувати за допомогою цього проекту – https://github.com/instabot-py/instabot.py.\\n\\nYevhenii Kanivets\\'s Blog\\nМій IoT набір, який я пізніше використовував для Instagram\\nАле ставити лайки рандомним користувачам було не дуже еффективно, тож я написав пошук в ширину і зібрав список підписників моїх підписників, що ймовірно могли про мене чути.\\n\\nУ результаті мій скрипт пропрацював близько 2 місяців запущений на Raspberry Pi вдень та вночі, збільшивши кількість моїх підписніків до 1000. Потім мені стало нудно і я перестав займатися цією “дуже важливою” справою.\\n\\nРезультати\\nЯ успішно завершив свій проект через 256 днів після його початку. Рівень моєї французької значно виріс. Крім того я дізнався та розповів про багато цікавих речей та подій. Нарешті мені вдалося розібратися з тим що так Instagram і навіщо він потрібен.\\n\\nНажаль Instagram перетворився у місце маніфестації свого “успіху” та марнування власного часу для більшості користувачів. Але не думаю, що проблема у самому ресурсі – він просто дав людям те, чого вони хотіли.\\n\\nМені дуже подобається освітній контент, що спрямовано на розвиток людини – звіти про івенти, подорожі, книги та фільми, лайфхаки. Загалом все, що несе у собі цінність для когось окрім самолюбства автора…\\n\\nERROR_TYPES: [\\'Fluency\\', \\'Grammar\\', \\'Punctuation\\', \\'Spelling\\']\\nFINAL ANSWER:'\n"
     ]
    }
   ],
   "source": [
    "from src.packages.constants.error_constants import ErrorConstants\n",
    "from src.packages.prompts.instruction_tuning_gec_prompts import InstructionTuningGecPrompts\n",
    "from ua_gec import Corpus\n",
    "corpus = Corpus(partition=\"train\", annotation_layer=\"gec-only\")\n",
    "for doc in corpus:\n",
    "    print(\"\\n---Source starts:---\\n\")\n",
    "    print(doc.source)         # \"I likes it.\"\n",
    "    print(\"\\n---Source ends:---\\n\")\n",
    "    print(\"\\n---Target starts:---\\n\")\n",
    "    print(doc.target)         # \"I like it.\"\n",
    "    print(\"\\n---Target ends---\\n\")\n",
    "    print(\"\\n---Annotation starts:---\\n\")\n",
    "    print(doc.annotated)      # <AnnotatedText(\"I {likes=>like} it.\")\n",
    "    print(doc.meta.region)    # \"Київська\"\n",
    "    print(\"\\n---Annotation ends\")\n",
    "    print(\"\\n---Prompt starts\")\n",
    "    prompt = InstructionTuningGecPrompts.PROMPT.format_prompt(\n",
    "        query=doc.source,\n",
    "        error_types=ErrorConstants.ERROR_TYPES\n",
    "    )\n",
    "    print(prompt)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
