{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (0.27.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (23.1)\r\n",
      "Requirement already satisfied: psutil in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (5.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (6.0)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (2.1.2)\r\n",
      "Requirement already satisfied: huggingface-hub in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (0.19.4)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (0.4.1)\r\n",
      "Requirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\r\n",
      "Requirement already satisfied: sympy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.12.1)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\r\n",
      "zsh:1: no matches found: huggingface_hub[cli]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "!pip install -U \"huggingface_hub[cli]\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T17:41:15.235623Z",
     "start_time": "2024-03-01T17:41:13.536582Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/rkovalch/miniconda3/envs/simulationllm/bin/huggingface-cli\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 49, in main\r\n",
      "    service.run()\r\n",
      "  File \"/Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages/huggingface_hub/commands/delete_cache.py\", line 137, in run\r\n",
      "    selected_hashes = _manual_review_tui(hf_cache_info, preselected=[])\r\n",
      "  File \"/Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages/huggingface_hub/commands/delete_cache.py\", line 86, in _inner\r\n",
      "    raise ImportError(\r\n",
      "ImportError: The `delete-cache` command requires extra dependencies to work with the TUI.\r\n",
      "Please run `pip install huggingface_hub[cli]` to install them.\r\n",
      "Otherwise, disable TUI using the `--disable-tui` flag.\r\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli delete-cache"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T17:41:34.261969Z",
     "start_time": "2024-03-01T17:41:33.874740Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f5425c445c9495bad7d51b1e05bd5b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "No chat template is defined for this tokenizer - using the default template for the LlamaTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poland, as a nation, doesn't physically travel to space. However, Poland has contributed to the field of space exploration through its scientists, engineers, and collaborations with international space agencies. The Polish Space Agency, established in 2016, aims to promote and coordinate the country's space activities.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, Conversation\n",
    "from src.packages.utils.parameter_server import ParameterServer\n",
    "import torch\n",
    "\n",
    "parameter_server = ParameterServer()\n",
    "\n",
    "base_model_name = \"bardsai/jaskier-7b-dpo-v6.1\"\n",
    "chatbot = pipeline(\"conversational\", model=base_model_name, torch_dtype=torch.half, device_map=parameter_server.settings.device)\n",
    "conversation = Conversation(\"Can Poland into space?\")\n",
    "conversation = chatbot(conversation)\n",
    "print(conversation.messages[-1][\"content\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:39:45.733637Z",
     "start_time": "2024-03-02T14:38:31.234989Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (0.42.0)\r\n",
      "Requirement already satisfied: scipy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from bitsandbytes) (1.11.3)\r\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from scipy->bitsandbytes) (1.24.4)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (0.28.0.dev0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (23.1)\r\n",
      "Requirement already satisfied: psutil in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (5.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (6.0)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (2.1.2)\r\n",
      "Requirement already satisfied: huggingface-hub in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (0.21.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (0.4.1)\r\n",
      "Requirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\r\n",
      "Requirement already satisfied: sympy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.12.1)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes\n",
    "!pip install accelerate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T11:15:46.305948Z",
     "start_time": "2024-03-02T11:15:43.703451Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.30 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (4.30.0)\r\n",
      "Requirement already satisfied: accelerate in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (0.28.0.dev0)\r\n",
      "Requirement already satisfied: bitsandbytes in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (0.42.0)\r\n",
      "Requirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (0.21.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (2023.10.3)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (0.4.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (4.66.1)\r\n",
      "Requirement already satisfied: psutil in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (5.9.0)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (2.3.0.dev20240301)\r\n",
      "Requirement already satisfied: scipy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from bitsandbytes) (1.11.3)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (2023.12.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (4.8.0)\r\n",
      "Requirement already satisfied: sympy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.30) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.30) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.30) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.30) (2023.7.22)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.31 accelerate bitsandbytes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T12:11:51.878124Z",
     "start_time": "2024-03-02T12:11:50.607695Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T12:16:15.397541Z",
     "start_time": "2024-03-02T12:16:15.373662Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\r\n",
      "  Cloning https://github.com/huggingface/transformers.git to /private/var/folders/gg/1kd93k4x47q5_gj92ljtjf000000gq/T/pip-req-build-38s7vmlf\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /private/var/folders/gg/1kd93k4x47q5_gj92ljtjf000000gq/T/pip-req-build-38s7vmlf\r\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 831bc25d8fdb85768402f772cf65cc3d7872b211\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (0.21.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (2023.10.3)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (2.31.0)\r\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.39.0.dev0)\r\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/01/04/45d88b8bddc09bf56ae1631721393255b75798af515c65c26389713a2072/tokenizers-0.15.2-cp310-cp310-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached tokenizers-0.15.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (0.4.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (4.66.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (2023.12.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (4.8.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (2023.7.22)\r\n",
      "Using cached tokenizers-0.15.2-cp310-cp310-macosx_11_0_arm64.whl (2.4 MB)\r\n",
      "Building wheels for collected packages: transformers\r\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for transformers: filename=transformers-4.39.0.dev0-py3-none-any.whl size=8593748 sha256=1749d90b38a8aa113244e31c097feb67e687b6731d409cd84e6f0b02a09ef003\r\n",
      "  Stored in directory: /private/var/folders/gg/1kd93k4x47q5_gj92ljtjf000000gq/T/pip-ephem-wheel-cache-le8hllh0/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\r\n",
      "Successfully built transformers\r\n",
      "Installing collected packages: tokenizers, transformers\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.13.3\r\n",
      "    Uninstalling tokenizers-0.13.3:\r\n",
      "      Successfully uninstalled tokenizers-0.13.3\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.30.0\r\n",
      "    Uninstalling transformers-4.30.0:\r\n",
      "      Successfully uninstalled transformers-4.30.0\r\n",
      "Successfully installed tokenizers-0.15.2 transformers-4.39.0.dev0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T12:13:10.077880Z",
     "start_time": "2024-03-02T12:12:48.113452Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: auto_gptq==0.2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: accelerate>=0.19.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (0.28.0.dev0)\r\n",
      "Requirement already satisfied: datasets in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (2.18.0)\r\n",
      "Requirement already satisfied: numpy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (1.24.4)\r\n",
      "Requirement already satisfied: rouge in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (1.0.1)\r\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (2.3.0.dev20240301)\r\n",
      "Requirement already satisfied: safetensors in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (0.4.1)\r\n",
      "Requirement already satisfied: transformers>=4.26.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from auto_gptq==0.2.0) (4.39.0.dev0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate>=0.19.0->auto_gptq==0.2.0) (23.1)\r\n",
      "Requirement already satisfied: psutil in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate>=0.19.0->auto_gptq==0.2.0) (5.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate>=0.19.0->auto_gptq==0.2.0) (6.0)\r\n",
      "Requirement already satisfied: huggingface-hub in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate>=0.19.0->auto_gptq==0.2.0) (0.21.3)\r\n",
      "Requirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.2.0) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.2.0) (4.8.0)\r\n",
      "Requirement already satisfied: sympy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.2.0) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.2.0) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.2.0) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.2.0) (2023.12.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers>=4.26.1->auto_gptq==0.2.0) (2023.10.3)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers>=4.26.1->auto_gptq==0.2.0) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers>=4.26.1->auto_gptq==0.2.0) (0.15.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers>=4.26.1->auto_gptq==0.2.0) (4.66.1)\r\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (14.0.0)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (1.5.3)\r\n",
      "Requirement already satisfied: xxhash in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (0.70.16)\r\n",
      "Requirement already satisfied: aiohttp in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->auto_gptq==0.2.0) (3.8.6)\r\n",
      "Requirement already satisfied: six in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from rouge->auto_gptq==0.2.0) (1.16.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (3.3.2)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (4.0.3)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.2.0) (1.3.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers>=4.26.1->auto_gptq==0.2.0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers>=4.26.1->auto_gptq==0.2.0) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers>=4.26.1->auto_gptq==0.2.0) (2023.7.22)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->auto_gptq==0.2.0) (2.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from pandas->datasets->auto_gptq==0.2.0) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from pandas->datasets->auto_gptq==0.2.0) (2023.3.post1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from sympy->torch>=1.13.0->auto_gptq==0.2.0) (1.3.0)\r\n",
      "Collecting transformers==4.30\r\n",
      "  Obtaining dependency information for transformers==4.30 from https://files.pythonhosted.org/packages/e2/72/1af3d38e98fdcceb3876de4567ac395a66c26976e259fe2d46266e052d61/transformers-4.30.0-py3-none-any.whl.metadata\r\n",
      "  Using cached transformers-4.30.0-py3-none-any.whl.metadata (113 kB)\r\n",
      "Requirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (0.21.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (2023.10.3)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (2.31.0)\r\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30)\r\n",
      "  Obtaining dependency information for tokenizers!=0.11.3,<0.14,>=0.11.1 from https://files.pythonhosted.org/packages/70/68/0a450e4dc488031b82fcd869840c542b86aad4a07d0eca1d7e9cbb9d742e/tokenizers-0.13.3-cp310-cp310-macosx_12_0_arm64.whl.metadata\r\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-macosx_12_0_arm64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (0.4.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.30) (4.66.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (2023.12.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (4.8.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.30) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.30) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.30) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.30) (2023.7.22)\r\n",
      "Using cached transformers-4.30.0-py3-none-any.whl (7.2 MB)\r\n",
      "Using cached tokenizers-0.13.3-cp310-cp310-macosx_12_0_arm64.whl (3.9 MB)\r\n",
      "Installing collected packages: tokenizers, transformers\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.15.2\r\n",
      "    Uninstalling tokenizers-0.15.2:\r\n",
      "      Successfully uninstalled tokenizers-0.15.2\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.39.0.dev0\r\n",
      "    Uninstalling transformers-4.39.0.dev0:\r\n",
      "      Successfully uninstalled transformers-4.39.0.dev0\r\n",
      "Successfully installed tokenizers-0.13.3 transformers-4.30.0\r\n",
      "Requirement already satisfied: optimum in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (1.17.1)\r\n",
      "Requirement already satisfied: coloredlogs in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (15.0.1)\r\n",
      "Requirement already satisfied: sympy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (1.12)\r\n",
      "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (4.30.0)\r\n",
      "Requirement already satisfied: torch>=1.11 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (2.3.0.dev20240301)\r\n",
      "Requirement already satisfied: packaging in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (23.1)\r\n",
      "Requirement already satisfied: numpy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (1.24.4)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (0.21.3)\r\n",
      "Requirement already satisfied: datasets in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from optimum) (2.18.0)\r\n",
      "Requirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2023.12.1)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.66.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.8.0)\r\n",
      "Requirement already satisfied: networkx in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (2023.10.3)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.4.1)\r\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.1.99)\r\n",
      "Requirement already satisfied: protobuf<=3.20.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (3.20.0)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\r\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (14.0.0)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (1.5.3)\r\n",
      "Requirement already satisfied: xxhash in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (0.70.16)\r\n",
      "Requirement already satisfied: aiohttp in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from datasets->optimum) (3.8.6)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (3.3.2)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2023.7.22)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum) (2.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.3.post1)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum) (1.16.0)\r\n",
      "Collecting git+https://github.com/huggingface/transformers.git\r\n",
      "  Cloning https://github.com/huggingface/transformers.git to /private/var/folders/gg/1kd93k4x47q5_gj92ljtjf000000gq/T/pip-req-build-n_6le_ho\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /private/var/folders/gg/1kd93k4x47q5_gj92ljtjf000000gq/T/pip-req-build-n_6le_ho\r\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 831bc25d8fdb85768402f772cf65cc3d7872b211\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (0.21.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (2023.10.3)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (2.31.0)\r\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.39.0.dev0)\r\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/01/04/45d88b8bddc09bf56ae1631721393255b75798af515c65c26389713a2072/tokenizers-0.15.2-cp310-cp310-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached tokenizers-0.15.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (0.4.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (4.66.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (2023.12.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (4.8.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (2023.7.22)\r\n",
      "Using cached tokenizers-0.15.2-cp310-cp310-macosx_11_0_arm64.whl (2.4 MB)\r\n",
      "Building wheels for collected packages: transformers\r\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for transformers: filename=transformers-4.39.0.dev0-py3-none-any.whl size=8593748 sha256=8582b3a200560e63ac486b9226a2679d96c94e716264de1024b777b6536bca5f\r\n",
      "  Stored in directory: /private/var/folders/gg/1kd93k4x47q5_gj92ljtjf000000gq/T/pip-ephem-wheel-cache-qqrixdxq/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\r\n",
      "Successfully built transformers\r\n",
      "Installing collected packages: tokenizers, transformers\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.13.3\r\n",
      "    Uninstalling tokenizers-0.13.3:\r\n",
      "      Successfully uninstalled tokenizers-0.13.3\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.30.0\r\n",
      "    Uninstalling transformers-4.30.0:\r\n",
      "      Successfully uninstalled transformers-4.30.0\r\n",
      "Successfully installed tokenizers-0.15.2 transformers-4.39.0.dev0\r\n",
      "Requirement already satisfied: accelerate in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (0.28.0.dev0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (23.1)\r\n",
      "Requirement already satisfied: psutil in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (5.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (6.0)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (2.3.0.dev20240301)\r\n",
      "Requirement already satisfied: huggingface-hub in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (0.21.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from accelerate) (0.4.1)\r\n",
      "Requirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\r\n",
      "Requirement already satisfied: sympy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.12.1)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install auto_gptq==0.2.0\n",
    "!pip install transformers==4.30\n",
    "!pip install --upgrade optimum\n",
    "!pip install --upgrade git+https://github.com/huggingface/transformers.git\n",
    "!pip install --upgrade accelerate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:35:52.948871Z",
     "start_time": "2024-03-02T14:35:21.978503Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0727a6bb1f3e4e779a4e7bb59d502572"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "auto-gptq is required in order to perform quantzation : `pip install auto-gptq`",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 19\u001B[0m\n\u001B[1;32m     11\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForCausalLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name, torch_dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat16)\n\u001B[1;32m     13\u001B[0m quantizer \u001B[38;5;241m=\u001B[39m GPTQQuantizer(\n\u001B[1;32m     14\u001B[0m     bits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m,\n\u001B[1;32m     15\u001B[0m     dataset\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mc4\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     16\u001B[0m     block_name_to_quantize\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel.decoder.layers\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     17\u001B[0m     model_seqlen \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2048\u001B[39m\n\u001B[1;32m     18\u001B[0m )\n\u001B[0;32m---> 19\u001B[0m quantized_model \u001B[38;5;241m=\u001B[39m \u001B[43mquantizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantize_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m save_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../models/jaskier-7b-dpo-v6.1-gptq-4bit\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     22\u001B[0m quantizer\u001B[38;5;241m.\u001B[39msave(model,save_folder)\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/optimum/gptq/quantizer.py:321\u001B[0m, in \u001B[0;36mGPTQQuantizer.quantize_model\u001B[0;34m(self, model, tokenizer)\u001B[0m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;124;03mQuantizes the model using the dataset\u001B[39;00m\n\u001B[1;32m    304\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;124;03m    `nn.Module`: The quantized model\u001B[39;00m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_auto_gptq_available():\n\u001B[0;32m--> 321\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto-gptq is required in order to perform quantzation : `pip install auto-gptq`\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    322\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m    323\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo GPU found. A GPU is needed to quantize model.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: auto-gptq is required in order to perform quantzation : `pip install auto-gptq`"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from src.packages.utils.parameter_server import ParameterServer\n",
    "from optimum.gptq import GPTQQuantizer, load_quantized_model\n",
    "\n",
    "parameter_server = ParameterServer()\n",
    "model_name = \"bardsai/jaskier-7b-dpo-v6.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "\n",
    "quantizer = GPTQQuantizer(\n",
    "    bits=4,\n",
    "    dataset=\"c4\",\n",
    "    block_name_to_quantize=\"model.decoder.layers\",\n",
    "    model_seqlen = 2048\n",
    ")\n",
    "quantized_model = quantizer.quantize_model(model, tokenizer)\n",
    "\n",
    "save_folder = \"../models/jaskier-7b-dpo-v6.1-gptq-4bit\"\n",
    "quantizer.save(model,save_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:36:29.720506Z",
     "start_time": "2024-03-02T14:35:58.602568Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 14\u001B[0m\n\u001B[1;32m      8\u001B[0m bnb_config \u001B[38;5;241m=\u001B[39m BitsAndBytesConfig(\n\u001B[1;32m      9\u001B[0m     load_in_4bit\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     10\u001B[0m     bnb_4bit_quant_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnf4\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     11\u001B[0m     bnb_4bit_compute_dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat16,\n\u001B[1;32m     12\u001B[0m )\n\u001B[1;32m     13\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbardsai/jaskier-7b-dpo-v6.1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 14\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquantization_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbnb_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameter_server\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msettings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m model\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSuccessfully loaded the model \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m into memory\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:563\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    561\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    562\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[0;32m--> 563\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    564\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    565\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    567\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    568\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    569\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/transformers/modeling_utils.py:3029\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   3026\u001B[0m     hf_quantizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   3028\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hf_quantizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 3029\u001B[0m     \u001B[43mhf_quantizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate_environment\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3030\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_tf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_flax\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\n\u001B[1;32m   3031\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3032\u001B[0m     torch_dtype \u001B[38;5;241m=\u001B[39m hf_quantizer\u001B[38;5;241m.\u001B[39mupdate_torch_dtype(torch_dtype)\n\u001B[1;32m   3033\u001B[0m     device_map \u001B[38;5;241m=\u001B[39m hf_quantizer\u001B[38;5;241m.\u001B[39mupdate_device_map(device_map)\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:62\u001B[0m, in \u001B[0;36mBnb4BitHfQuantizer.validate_environment\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalidate_environment\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (is_accelerate_available() \u001B[38;5;129;01mand\u001B[39;00m is_bitsandbytes_available()):\n\u001B[0;32m---> 62\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m     63\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     64\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     65\u001B[0m         )\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom_tf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom_flax\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m     68\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     69\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     70\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m sure the weights are in PyTorch format.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     71\u001B[0m         )\n",
      "\u001B[0;31mImportError\u001B[0m: Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from src.packages.utils.parameter_server import ParameterServer\n",
    "\n",
    "parameter_server = ParameterServer()\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "model_name = \"bardsai/jaskier-7b-dpo-v6.1\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    device=parameter_server.settings.device,\n",
    ")\n",
    "model.config.use_cache = False\n",
    "\n",
    "print(f\"Successfully loaded the model {model_name} into memory\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T12:16:09.874089Z",
     "start_time": "2024-03-02T12:16:09.490457Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      5\u001B[0m parameter_server \u001B[38;5;241m=\u001B[39m ParameterServer()\n\u001B[0;32m----> 6\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbardsai/jaskier-7b-dpo-v6.1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mload_in_4bit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m#llm_int8_enable_fp32_cpu_offload=True,\u001B[39;49;00m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameter_server\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msettings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameter_server\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msettings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m model\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:561\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    559\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    560\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[0;32m--> 561\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    562\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    563\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    564\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    565\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    566\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    567\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/transformers/modeling_utils.py:3024\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   3021\u001B[0m     hf_quantizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   3023\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hf_quantizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 3024\u001B[0m     \u001B[43mhf_quantizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate_environment\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3025\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_tf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_flax\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\n\u001B[1;32m   3026\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3027\u001B[0m     torch_dtype \u001B[38;5;241m=\u001B[39m hf_quantizer\u001B[38;5;241m.\u001B[39mupdate_torch_dtype(torch_dtype)\n\u001B[1;32m   3028\u001B[0m     device_map \u001B[38;5;241m=\u001B[39m hf_quantizer\u001B[38;5;241m.\u001B[39mupdate_device_map(device_map)\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:62\u001B[0m, in \u001B[0;36mBnb4BitHfQuantizer.validate_environment\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalidate_environment\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (is_accelerate_available() \u001B[38;5;129;01mand\u001B[39;00m is_bitsandbytes_available()):\n\u001B[0;32m---> 62\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m     63\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     64\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     65\u001B[0m         )\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom_tf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom_flax\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m     68\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     69\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     70\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m sure the weights are in PyTorch format.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     71\u001B[0m         )\n",
      "\u001B[0;31mImportError\u001B[0m: Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import pipeline, Conversation\n",
    "from src.packages.utils.parameter_server import ParameterServer\n",
    "import torch\n",
    "parameter_server = ParameterServer()\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"bardsai/jaskier-7b-dpo-v6.1\",\n",
    "    load_in_4bit=True,\n",
    "    #llm_int8_enable_fp32_cpu_offload=True,\n",
    "    device_map=parameter_server.settings.device,\n",
    "    device=parameter_server.settings.device,\n",
    ")\n",
    "model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T11:27:45.773875Z",
     "start_time": "2024-03-02T11:27:45.502480Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\r\n",
      "  Obtaining dependency information for peft from https://files.pythonhosted.org/packages/08/87/3e7eb34ac06d3f4ac72e2302e9e69bef12247a8a627c59a4d8a498135727/peft-0.9.0-py3-none-any.whl.metadata\r\n",
      "  Downloading peft-0.9.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from peft) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from peft) (23.1)\r\n",
      "Requirement already satisfied: psutil in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from peft) (5.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from peft) (6.0)\r\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from peft) (2.1.2)\r\n",
      "Requirement already satisfied: transformers in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from peft) (4.35.2)\r\n",
      "Requirement already satisfied: tqdm in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from peft) (4.66.1)\r\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from peft) (0.27.2)\r\n",
      "Requirement already satisfied: safetensors in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from peft) (0.4.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from peft) (0.19.4)\r\n",
      "Requirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.12.1)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.8.0)\r\n",
      "Requirement already satisfied: sympy in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers->peft) (2023.10.3)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from transformers->peft) (0.15.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.7.22)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\r\n",
      "Downloading peft-0.9.0-py3-none-any.whl (190 kB)\r\n",
      "\u001B[2K   \u001B[90m\u001B[0m \u001B[32m190.9/190.9 kB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: peft\r\n",
      "Successfully installed peft-0.9.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T15:41:09.520267Z",
     "start_time": "2024-03-01T15:41:07.217427Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model = chatbot.model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T20:22:49.493453Z",
     "start_time": "2024-03-01T20:22:49.488485Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "MistralForCausalLM(\n  (model): MistralModel(\n    (embed_tokens): Embedding(32000, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x MistralDecoderLayer(\n        (self_attn): MistralAttention(\n          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): MistralRotaryEmbedding()\n        )\n        (mlp): MistralMLP(\n          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): MistralRMSNorm()\n        (post_attention_layernorm): MistralRMSNorm()\n      )\n    )\n    (norm): MistralRMSNorm()\n  )\n  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T17:19:56.057036Z",
     "start_time": "2024-03-01T17:19:56.045700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "trainable params: 1,703,936 || all params: 7,243,436,032 || trainable%: 0.023523863432663224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    inference_mode=False,\n",
    "    r=4,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.print_trainable_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:44:32.884440Z",
     "start_time": "2024-03-02T14:44:32.821912Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ua_gec\r\n",
      "  Obtaining dependency information for ua_gec from https://files.pythonhosted.org/packages/5b/be/7366527adb1982b877ac9f176e1bca31a3104d59937b40ed6f46dd75ac4d/ua_gec-2.1.3-py3-none-any.whl.metadata\r\n",
      "  Downloading ua_gec-2.1.3-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Downloading ua_gec-2.1.3-py3-none-any.whl (36.0 MB)\r\n",
      "\u001B[2K   \u001B[90m\u001B[0m \u001B[32m36.0/36.0 MB\u001B[0m \u001B[31m39.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: ua_gec\r\n",
      "Successfully installed ua_gec-2.1.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ua_gec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T16:34:22.012229Z",
     "start_time": "2024-03-01T16:34:12.559725Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  _   _          _      _\r\n",
      " | | | |_ __  __| |__ _| |_ ___\r\n",
      " | |_| | '_ \\/ _` / _` |  _/ -_)\r\n",
      "  \\___/| .__/\\__,_\\__,_|\\__\\___|\r\n",
      "       |_|\r\n",
      "                       \r\n",
      "Read the migration plan to Notebook 7 to learn about the new features and the actions to take if you are using extensions.\r\n",
      "\r\n",
      "https://jupyter-notebook.readthedocs.io/en/latest/migrate_to_notebook7.html\r\n",
      "\r\n",
      "Please note that updating to Notebook 7 might break some of your extensions.\r\n",
      "\r\n",
      "\u001B[33m[W 18:35:23.186 NotebookApp]\u001B[m Loading JupyterLab as a classic notebook (v6) extension.\r\n",
      "\u001B[33m[W 2024-03-01 18:35:23.188 LabApp]\u001B[m 'iopub_data_rate_limit' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\r\n",
      "\u001B[33m[W 2024-03-01 18:35:23.188 LabApp]\u001B[m 'iopub_data_rate_limit' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\r\n",
      "\u001B[32m[I 2024-03-01 18:35:23.190 LabApp]\u001B[m JupyterLab extension loaded from /Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages/jupyterlab\r\n",
      "\u001B[32m[I 2024-03-01 18:35:23.190 LabApp]\u001B[m JupyterLab application directory is /Users/rkovalch/miniconda3/envs/simulationllm/share/jupyter/lab\r\n",
      "\u001B[32m[I 18:35:23.192 NotebookApp]\u001B[m The port 8888 is already in use, trying another port.\r\n",
      "\u001B[32m[I 18:35:23.193 NotebookApp]\u001B[m Serving notebooks from local directory: /Users/rkovalch/Documents/UCU/ua-gec-lora/notebooks\r\n",
      "\u001B[32m[I 18:35:23.193 NotebookApp]\u001B[m Jupyter Notebook 6.5.4 is running at:\r\n",
      "\u001B[32m[I 18:35:23.193 NotebookApp]\u001B[m http://localhost:8889/?token=007542e6bbff700fcc1b2771e82589d305b71878e9f718dc\r\n",
      "\u001B[32m[I 18:35:23.193 NotebookApp]\u001B[m  or http://127.0.0.1:8889/?token=007542e6bbff700fcc1b2771e82589d305b71878e9f718dc\r\n",
      "\u001B[32m[I 18:35:23.193 NotebookApp]\u001B[m Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\r\n",
      "\u001B[35m[C 18:35:23.196 NotebookApp]\u001B[m \r\n",
      "    \r\n",
      "    To access the notebook, open this file in a browser:\r\n",
      "        file:///Users/rkovalch/Library/Jupyter/runtime/nbserver-35788-open.html\r\n",
      "    Or copy and paste one of these URLs:\r\n",
      "        http://localhost:8889/?token=007542e6bbff700fcc1b2771e82589d305b71878e9f718dc\r\n",
      "     or http://127.0.0.1:8889/?token=007542e6bbff700fcc1b2771e82589d305b71878e9f718dc\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T16:35:41.385539Z",
     "start_time": "2024-03-01T16:35:21.723006Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "LlamaTokenizerFast(name_or_path='bardsai/jaskier-7b-dpo-v6.1', vocab_size=32000, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:46:10.356593Z",
     "start_time": "2024-03-02T14:46:10.176812Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "PeftModelForSeq2SeqLM(\n  (base_model): LoraModel(\n    (model): MistralForCausalLM(\n      (model): MistralModel(\n        (embed_tokens): Embedding(32000, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x MistralDecoderLayer(\n            (self_attn): MistralSdpaAttention(\n              (q_proj): lora.Linear(\n                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=4, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=4, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n              (v_proj): lora.Linear(\n                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=4, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=4, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n              (rotary_emb): MistralRotaryEmbedding()\n            )\n            (mlp): MistralMLP(\n              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): MistralRMSNorm()\n            (post_attention_layernorm): MistralRMSNorm()\n          )\n        )\n        (norm): MistralRMSNorm()\n      )\n      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n    )\n  )\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:44:43.660556Z",
     "start_time": "2024-03-02T14:44:43.656879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Source starts:---\n",
      "\n",
      "Byte for France       Instagram\n",
      " 3           ,                    .\n",
      "\n",
      "          Instagram.      ,        https://www.instagram.com/yevhenii_kanivets/\n",
      "\n",
      "  Instagram\n",
      "    ,       .     ,                .\n",
      "\n",
      "         .      ?  !\n",
      "\n",
      "Instagram     :\n",
      "\n",
      "      (     ,  )\n",
      "  -      (    )\n",
      "  ,        \n",
      " ,        ,         Instagram    .    ?\n",
      "\n",
      "Byte for France\n",
      "        .     .     ,          . ,          .\n",
      "\n",
      ",    ,    ,      .        ?  ?\n",
      "\n",
      "        .   ,   ,    .        Byte For France  Instagram-,        ( )          .\n",
      "\n",
      " \n",
      "     3-  2018 .    ,       .         ,    .\n",
      "\n",
      "Yevhenii Kanivets's Blog\n",
      "  \n",
      "   ,       ,    , ,  Instagram,     .       .\n",
      "\n",
      " ,    Instagram       (  ).                  .\n",
      "\n",
      "   .       ,           .       ,      .\n",
      "\n",
      "         ,         ,   .\n",
      "\n",
      "  \n",
      "  ,    .     .                .    ,             .\n",
      "\n",
      "      ,       .  ,      ,     .\n",
      "\n",
      "   , ,      .        ,  .\n",
      "\n",
      "  ?\n",
      "Instagram   ,        .            .     ,       .\n",
      "\n",
      "          ( , )      Instagram,        .\n",
      "\n",
      " ,                 ,     .    /      .\n",
      "\n",
      "   ,            .  (  )    ,     ,      .\n",
      "\n",
      " ,           ,   ,         .      Instagram,   ?\n",
      "\n",
      "   ?\n",
      "   Instagram-,  ,       .         (     ),  ,      .\n",
      "\n",
      "        ,           https://github.com/instabot-py/instabot.py.\n",
      "\n",
      "Yevhenii Kanivets's Blog\n",
      " IoT ,      Instagram\n",
      "        ,            ,      .\n",
      "\n",
      "      2    Raspberry Pi   ,      1000.            .\n",
      "\n",
      "\n",
      "      256    .     .            .         Instagram    .\n",
      "\n",
      " Instagram             .   ,           ,   .\n",
      "\n",
      "    ,         , ,   , .  ,          \n",
      "\n",
      "\n",
      "---Source ends:---\n",
      "\n",
      "\n",
      "---Target starts:---\n",
      "\n",
      "Byte for France       Instagram\n",
      " 3           ,            ,        .\n",
      "\n",
      "   ,       Instagram.      ,        https://www.instagram.com/yevhenii_kanivets/\n",
      "\n",
      "  Instagram\n",
      "           .     ,      ,          .\n",
      "\n",
      "         .      ?  !\n",
      "\n",
      "Instagram     :\n",
      "\n",
      "      (     ,  );\n",
      "        (    );\n",
      "  ,        ;\n",
      " ,        ,         Instagram    .    ?\n",
      "\n",
      "Byte for France\n",
      "        .     .  ,   ,          . ,          .\n",
      "\n",
      ",    ,    ,      .        ?  ?\n",
      "\n",
      "         .  ,   ,    .        Byte For France  Instagram-,        ( )          .\n",
      "\n",
      " \n",
      "     3-  2018 .    ,       .         ,    .\n",
      "\n",
      "Yevhenii Kanivets's Blog\n",
      "  \n",
      "   ,     ,    , ,  Instagram,     .       .\n",
      "\n",
      " ,    Instagram       (  ).   ,               .\n",
      "\n",
      "   .       ,           .  ,     ,   ,   .\n",
      "\n",
      " ,        ,        ,   .\n",
      "\n",
      "  \n",
      "  ,    .     .                .    ,             .\n",
      "\n",
      "      ,       .  ,      ,     .\n",
      "\n",
      "   , ,     .        ,  .\n",
      "\n",
      "  ?\n",
      "Instagram   ,        .        ,    .     ,       .\n",
      "\n",
      "          ( , )      Instagram,        .\n",
      "\n",
      " ,      ,           ,     .    /      .\n",
      "\n",
      "   ,            .  (  )    ,       ,      .\n",
      "\n",
      " ,           ,   ,   ,      .      Instagram,   ?\n",
      "\n",
      "   ?\n",
      "   Instagram-,  ,       .         (     ),  ,      .\n",
      "\n",
      "        ,           https://github.com/instabot-py/instabot.py.\n",
      "\n",
      "Yevhenii Kanivets's Blog\n",
      " IoT ,      Instagram.\n",
      "        ,            ,      .\n",
      "\n",
      "   ,   Raspberry Pi,   2     ,      1000.    ,        .\n",
      "\n",
      "\n",
      "      256    .     .  ,          .      ,   Instagram    .\n",
      "\n",
      " , Instagram             .   ,           ,   .\n",
      "\n",
      "    ,         , ,   , .  ,       ,   \n",
      "\n",
      "\n",
      "---Target ends---\n",
      "\n",
      "\n",
      "---Annotation starts:---\n",
      "\n",
      "Byte for France      {=>:::error_type=Spelling} Instagram\n",
      " 3           ,            {=>,:::error_type=Punctuation}        .\n",
      "\n",
      "   {=>,:::error_type=Punctuation}      {=>:::error_type=Spelling} Instagram.      ,       {=>:::error_type=Punctuation} https://www.instagram.com/yevhenii_kanivets/\n",
      "\n",
      "  Instagram\n",
      "    {,=>:::error_type=Punctuation}     {=>:::error_type=Spelling}  .     ,      {=>,:::error_type=Punctuation}   {=>:::error_type=Spelling}       .\n",
      "\n",
      "       {=>:::error_type=Spelling}  .   {=>:::error_type=G/Case}   ?  !\n",
      "\n",
      "Instagram     :\n",
      "\n",
      "      ( {=>:::error_type=Punctuation}    , {=>:::error_type=Spelling} ){=>;:::error_type=Punctuation}\n",
      "  {-=>:::error_type=Spelling}      ({=>:::error_type=Spelling}    ){=>;:::error_type=Punctuation}\n",
      "  ,        {=>;:::error_type=Punctuation}\n",
      " {=>:::error_type=Spelling},        ,         Instagram    .    ?\n",
      "\n",
      "Byte for France\n",
      "        .     .  {=>,:::error_type=Punctuation}   ,          . ,          .\n",
      "\n",
      ",    ,    ,      .        ?  ?\n",
      "\n",
      "        {=> :::error_type=Spelling}.  { =>:::error_type=G/Case},   ,    .     {=>:::error_type=Spelling}   Byte For France {=>:::error_type=Punctuation} Instagram-,     {=>:::error_type=Spelling}   ( )          .\n",
      "\n",
      " \n",
      "     3-  2018 .    ,       .         ,   {=>:::error_type=Spelling} .\n",
      "\n",
      "Yevhenii Kanivets's Blog\n",
      "  \n",
      "   ,  { =>:::error_type=Spelling}{ =>:::error_type=G/VerbAForm}   ,    , ,  Instagram,     .       .\n",
      "\n",
      " ,    Instagram       (  ).   {=>,:::error_type=Punctuation}               .\n",
      "\n",
      " {=>:::error_type=G/VerbVoice}  .       ,        {=>:::error_type=G/Case}   .  {=>,:::error_type=Punctuation}     ,   {=>,:::error_type=Punctuation}   .\n",
      "\n",
      " {=>,:::error_type=Punctuation}        ,    { =>:::error_type=Spelling}    ,   .\n",
      "\n",
      "  \n",
      "  ,    .     .     { => :::error_type=G/Gender}     {=>:::error_type=Punctuation}     .    ,             .\n",
      "\n",
      "      ,       .  ,      ,     .\n",
      "\n",
      "   , ,  {  => :::error_type=G/Case}  {=>:::error_type=G/Case}.        ,  .\n",
      "\n",
      "  ?\n",
      "Instagram   ,        .        {=>,:::error_type=Punctuation}    .     ,       .\n",
      "\n",
      "          ( , )      Instagram,        .\n",
      "\n",
      " ,      {=>,:::error_type=Punctuation}     {  =>  :::error_type=G/Case}    ,     .    /      .\n",
      "\n",
      "   ,   {=>:::error_type=Spelling}     {=>:::error_type=Punctuation}    .  (  )    {=>:::error_type=Spelling},    {=>  :::error_type=G/UngrammaticalStructure} ,  {=>:::error_type=Spelling}    .\n",
      "\n",
      " ,           , {=>:::error_type=Spelling}  ,   {=>:::error_type=G/Case}{=>,:::error_type=Punctuation}      .      Instagram,   ?\n",
      "\n",
      "   ?\n",
      "   Instagram-,  ,       .         (     ),  ,      .\n",
      "\n",
      " {=>:::error_type=Spelling}       ,          {=>:::error_type=Punctuation} https://github.com/instabot-py/instabot.py.\n",
      "\n",
      "Yevhenii Kanivets's Blog\n",
      " IoT ,      Instagram{=>.:::error_type=Punctuation}\n",
      "        {=>:::error_type=Spelling},     {=>:::error_type=Spelling}       ,      .\n",
      "\n",
      "   {=>,   Raspberry Pi,:::error_type=G/UngrammaticalStructure}   2  {  Raspberry Pi=>:::error_type=G/UngrammaticalStructure} {=>:::error_type=Spelling}  ,      1000.    {=>,:::error_type=Punctuation}        .\n",
      "\n",
      "\n",
      "      256    .     .  {=>,:::error_type=Punctuation}   {=>:::error_type=Spelling}       .      {=>,:::error_type=Punctuation}  {=>:::error_type=Spelling} Instagram    .\n",
      "\n",
      "{=> :::error_type=Spelling}{=>,:::error_type=Punctuation} Instagram  {=>:::error_type=G/Prep}           .   ,      {=>:::error_type=Punctuation}     ,   .\n",
      "\n",
      "    , {=>:::error_type=G/Conjunction}     {=>:::error_type=Punctuation}   , ,   , .  {=>:::error_type=Spelling},       {=>,:::error_type=Punctuation}   \n",
      "\n",
      "\n",
      "\n",
      "---Annotation ends\n",
      "\n",
      "---Prompt starts\n",
      "text='Given (\"SOURCE\") text, correct errors if present, fulfilling GEC (Grammar Error Correction) Task for Ukrainian Language.\\nUse following set of errors (\"ERROR_TYPES\"):\\n[\\'Fluency\\', \\'Grammar\\', \\'Punctuation\\', \\'Spelling\\']\\nIf you would detect error (\"ERROR\"), generate correction (\"CORRECTION\") following the structure and specifying error type (\"ERROR_TYPE\"):\\n{(\"ERROR\")=>(\"CORRECTION\"):::(\"ERROR_TYPE\")}\\nOtherwise keep original text.\\n\\nSOURCE: Byte for France       Instagram\\n 3           ,                    .\\n\\n          Instagram.      ,        https://www.instagram.com/yevhenii_kanivets/\\n\\n  Instagram\\n    ,       .     ,                .\\n\\n         .      ?  !\\n\\nInstagram     :\\n\\n      (     ,  )\\n  -      (    )\\n  ,        \\n ,        ,         Instagram    .    ?\\n\\nByte for France\\n        .     .     ,          . ,          .\\n\\n,    ,    ,      .        ?  ?\\n\\n        .   ,   ,    .        Byte For France  Instagram-,        ( )          .\\n\\n \\n     3-  2018 .    ,       .         ,    .\\n\\nYevhenii Kanivets\\'s Blog\\n  \\n   ,       ,    , ,  Instagram,     .       .\\n\\n ,    Instagram       (  ).                  .\\n\\n   .       ,           .       ,      .\\n\\n         ,         ,   .\\n\\n  \\n  ,    .     .                .    ,             .\\n\\n      ,       .  ,      ,     .\\n\\n   , ,      .        ,  .\\n\\n  ?\\nInstagram   ,        .            .     ,       .\\n\\n          ( , )      Instagram,        .\\n\\n ,                 ,     .    /      .\\n\\n   ,            .  (  )    ,     ,      .\\n\\n ,           ,   ,         .      Instagram,   ?\\n\\n   ?\\n   Instagram-,  ,       .         (     ),  ,      .\\n\\n        ,           https://github.com/instabot-py/instabot.py.\\n\\nYevhenii Kanivets\\'s Blog\\n IoT ,      Instagram\\n        ,            ,      .\\n\\n      2    Raspberry Pi   ,      1000.            .\\n\\n\\n      256    .     .            .         Instagram    .\\n\\n Instagram             .   ,           ,   .\\n\\n    ,         , ,   , .  ,          \\n\\nERROR_TYPES: [\\'Fluency\\', \\'Grammar\\', \\'Punctuation\\', \\'Spelling\\']\\nFINAL ANSWER:'\n"
     ]
    }
   ],
   "source": [
    "from src.packages.constants.error_constants import ErrorConstants\n",
    "from src.packages.prompts.instruction_tuning_gec_prompts import InstructionTuningGecPrompts\n",
    "from ua_gec import Corpus\n",
    "corpus = Corpus(partition=\"train\", annotation_layer=\"gec-only\")\n",
    "for doc in corpus:\n",
    "    print(\"\\n---Source starts:---\\n\")\n",
    "    print(doc.source)         # \"I likes it.\"\n",
    "    print(\"\\n---Source ends:---\\n\")\n",
    "    print(\"\\n---Target starts:---\\n\")\n",
    "    print(doc.target)         # \"I like it.\"\n",
    "    print(\"\\n---Target ends---\\n\")\n",
    "    print(\"\\n---Annotation starts:---\\n\")\n",
    "    print(doc.annotated)      # <AnnotatedText(\"I {likes=>like} it.\")\n",
    "    print(doc.meta.region)    # \"\"\n",
    "    print(\"\\n---Annotation ends\")\n",
    "    print(\"\\n---Prompt starts\")\n",
    "    prompt = InstructionTuningGecPrompts.PROMPT.format_prompt(\n",
    "        query=doc.source,\n",
    "        error_types=ErrorConstants.ERROR_TYPES\n",
    "    )\n",
    "    print(prompt)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T20:22:59.708257Z",
     "start_time": "2024-03-01T20:22:59.634903Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation = Conversation(\",    ?\")\n",
    "conversation = chatbot(conversation)\n",
    "print(conversation.messages[-1][\"content\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T20:30:52.839844Z",
     "start_time": "2024-03-01T20:28:00.194283Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'Given (\"SOURCE\") text, correct errors if present, fulfilling GEC (Grammar Error Correction) Task for Ukrainian Language.\\nUse following set of errors (\"ERROR_TYPES\"):\\n[\\'Fluency\\', \\'Grammar\\', \\'Punctuation\\', \\'Spelling\\']\\nIf you would detect error (\"ERROR\"), generate correction (\"CORRECTION\") following the structure and specifying error type (\"ERROR_TYPE\"):\\n{(\"ERROR\")=>(\"CORRECTION\"):::(\"ERROR_TYPE\")}\\nOtherwise keep original text.\\n\\nSOURCE: Byte for France       Instagram\\n 3           ,                    .\\n\\n          Instagram.      ,        https://www.instagram.com/yevhenii_kanivets/\\n\\n  Instagram\\n    ,       .     ,                .\\n\\n         .      ?  !\\n\\nInstagram     :\\n\\n      (     ,  )\\n  -      (    )\\n  ,        \\n ,        ,         Instagram    .    ?\\n\\nByte for France\\n        .     .     ,          . ,          .\\n\\n,    ,    ,      .        ?  ?\\n\\n        .   ,   ,    .        Byte For France  Instagram-,        ( )          .\\n\\n \\n     3-  2018 .    ,       .         ,    .\\n\\nYevhenii Kanivets\\'s Blog\\n  \\n   ,       ,    , ,  Instagram,     .       .\\n\\n ,    Instagram       (  ).                  .\\n\\n   .       ,           .       ,      .\\n\\n         ,         ,   .\\n\\n  \\n  ,    .     .                .    ,             .\\n\\n      ,       .  ,      ,     .\\n\\n   , ,      .        ,  .\\n\\n  ?\\nInstagram   ,        .            .     ,       .\\n\\n          ( , )      Instagram,        .\\n\\n ,                 ,     .    /      .\\n\\n   ,            .  (  )    ,     ,      .\\n\\n ,           ,   ,         .      Instagram,   ?\\n\\n   ?\\n   Instagram-,  ,       .         (     ),  ,      .\\n\\n        ,           https://github.com/instabot-py/instabot.py.\\n\\nYevhenii Kanivets\\'s Blog\\n IoT ,      Instagram\\n        ,            ,      .\\n\\n      2    Raspberry Pi   ,      1000.            .\\n\\n\\n      256    .     .            .         Instagram    .\\n\\n Instagram             .   ,           ,   .\\n\\n    ,         , ,   , .  ,          \\n\\nERROR_TYPES: [\\'Fluency\\', \\'Grammar\\', \\'Punctuation\\', \\'Spelling\\']\\nFINAL ANSWER:'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_string()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T20:27:29.517626Z",
     "start_time": "2024-03-01T20:27:29.486153Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ua_gec import AnnotationLayer\n",
    "\n",
    "AnnotationLayer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MistralForCausalLM' object has no attribute 'print_trainable_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/peft/tuners/lora/model.py:273\u001B[0m, in \u001B[0;36mLoraModel.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 273\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattr__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# defer to nn.Module's logic\u001B[39;00m\n\u001B[1;32m    274\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1694\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1695\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'LoraModel' object has no attribute 'print_trainable_parameters'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 13\u001B[0m\n\u001B[1;32m      4\u001B[0m config \u001B[38;5;241m=\u001B[39m LoraConfig(\n\u001B[1;32m      5\u001B[0m     task_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSEQ_2_SEQ_LM\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      6\u001B[0m     r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      9\u001B[0m     lora_dropout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m,\n\u001B[1;32m     10\u001B[0m )\n\u001B[1;32m     12\u001B[0m lora_model \u001B[38;5;241m=\u001B[39m LoraModel(model, config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 13\u001B[0m \u001B[43mlora_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprint_trainable_parameters\u001B[49m()\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/peft/tuners/lora/model.py:275\u001B[0m, in \u001B[0;36mLoraModel.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattr__\u001B[39m(name)  \u001B[38;5;66;03m# defer to nn.Module's logic\u001B[39;00m\n\u001B[1;32m    274\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\u001B[0;32m--> 275\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1693\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[1;32m   1694\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1695\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'MistralForCausalLM' object has no attribute 'print_trainable_parameters'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import LoraModel, LoraConfig\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.01,\n",
    ")\n",
    "\n",
    "lora_model = LoraModel(model, config, \"default\")\n",
    "lora_model.print_trainable_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T16:18:10.721448Z",
     "start_time": "2024-03-01T16:18:10.423551Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "MistralForCausalLM(\n  (model): MistralModel(\n    (embed_tokens): Embedding(32000, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x MistralDecoderLayer(\n        (self_attn): MistralAttention(\n          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): MistralRotaryEmbedding()\n        )\n        (mlp): MistralMLP(\n          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): MistralRMSNorm()\n        (post_attention_layernorm): MistralRMSNorm()\n      )\n    )\n    (norm): MistralRMSNorm()\n  )\n  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:04:15.775935Z",
     "start_time": "2024-03-01T13:04:15.773282Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a classic one for you: Why don't scientists trust atoms? Because they make up everything, and sometimes they just seem unpredictable!\n"
     ]
    }
   ],
   "source": [
    "conversation = Conversation(\"Tell me a joke\")\n",
    "conversation = chatbot(conversation)\n",
    "print(conversation.messages[-1][\"content\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:15:47.136845Z",
     "start_time": "2024-03-01T13:15:36.524085Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-01T08:48:52.545665Z",
     "start_time": "2024-03-01T08:47:41.378513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device=mps\n",
      "Loading model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rkovalch/miniconda3/envs/simulationllm/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load model: 71.10 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": "Transformer(\n  (token_embd): Embedding()\n  (blk): ModuleList(\n    (0-31): 32 x TransformerBlock(\n      (attn_norm): RMSNorm()\n      (attn_q): Linear()\n      (attn_k): Linear()\n      (attn_v): Linear()\n      (attn_output): Linear()\n      (ffn_norm): RMSNorm()\n      (ffn_gate): Linear()\n      (ffn_up): Linear()\n      (ffn_down): Linear()\n    )\n  )\n  (output_norm): RMSNorm()\n  (output): Linear()\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from src.packages.utils.parameter_server import ParameterServer\n",
    "from src.packages.training.load_from_bin import load_from_bin\n",
    "\n",
    "parameter_server = ParameterServer()\n",
    "\n",
    "model = load_from_bin(\n",
    "    checkpoint_path=Path(\"/Users/rkovalch/Documents/UCU/llama-cpp-torch/jaskier-f16\"),\n",
    "    device=parameter_server.settings.device\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed locating file constants.pkl: file not found",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m state_dict \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/Users/rkovalch/Documents/UCU/llama-cpp-torch/jaskier-f16/pytorch_model.bin\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/torch/jit/_serialization.py:162\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, _extra_files, _restore_shapes)\u001B[0m\n\u001B[1;32m    160\u001B[0m cu \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39mCompilationUnit()\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(f, (\u001B[38;5;28mstr\u001B[39m, pathlib\u001B[38;5;241m.\u001B[39mPath)):\n\u001B[0;32m--> 162\u001B[0m     cpp_module \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_ir_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_extra_files\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_restore_shapes\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    164\u001B[0m     cpp_module \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39mimport_ir_module_from_buffer(\n\u001B[1;32m    165\u001B[0m         cu, f\u001B[38;5;241m.\u001B[39mread(), map_location, _extra_files, _restore_shapes\n\u001B[1;32m    166\u001B[0m     )  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: PytorchStreamReader failed locating file constants.pkl: file not found"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "state_dict = torch.load(Path(\"/Users/rkovalch/Documents/UCU/llama-cpp-torch/jaskier-f16/pytorch_model.bin\"))\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T09:07:00.836669Z",
     "start_time": "2024-03-01T09:07:00.793333Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['token_embd.weight', 'token_embd.weight_type', 'blk.0.attn_norm.weight', 'blk.0.attn_norm.weight_type', 'blk.0.ffn_down.weight', 'blk.0.ffn_down.weight_type', 'blk.0.ffn_gate.weight', 'blk.0.ffn_gate.weight_type', 'blk.0.ffn_up.weight', 'blk.0.ffn_up.weight_type', 'blk.0.ffn_norm.weight', 'blk.0.ffn_norm.weight_type', 'blk.0.attn_k.weight', 'blk.0.attn_k.weight_type', 'blk.0.attn_output.weight', 'blk.0.attn_output.weight_type', 'blk.0.attn_q.weight', 'blk.0.attn_q.weight_type', 'blk.0.attn_v.weight', 'blk.0.attn_v.weight_type', 'blk.1.attn_norm.weight', 'blk.1.attn_norm.weight_type', 'blk.1.ffn_down.weight', 'blk.1.ffn_down.weight_type', 'blk.1.ffn_gate.weight', 'blk.1.ffn_gate.weight_type', 'blk.1.ffn_up.weight', 'blk.1.ffn_up.weight_type', 'blk.1.ffn_norm.weight', 'blk.1.ffn_norm.weight_type', 'blk.1.attn_k.weight', 'blk.1.attn_k.weight_type', 'blk.1.attn_output.weight', 'blk.1.attn_output.weight_type', 'blk.1.attn_q.weight', 'blk.1.attn_q.weight_type', 'blk.1.attn_v.weight', 'blk.1.attn_v.weight_type', 'blk.10.ffn_gate.weight', 'blk.10.ffn_gate.weight_type', 'blk.10.ffn_up.weight', 'blk.10.ffn_up.weight_type', 'blk.10.attn_k.weight', 'blk.10.attn_k.weight_type', 'blk.10.attn_output.weight', 'blk.10.attn_output.weight_type', 'blk.10.attn_q.weight', 'blk.10.attn_q.weight_type', 'blk.10.attn_v.weight', 'blk.10.attn_v.weight_type', 'blk.2.attn_norm.weight', 'blk.2.attn_norm.weight_type', 'blk.2.ffn_down.weight', 'blk.2.ffn_down.weight_type', 'blk.2.ffn_gate.weight', 'blk.2.ffn_gate.weight_type', 'blk.2.ffn_up.weight', 'blk.2.ffn_up.weight_type', 'blk.2.ffn_norm.weight', 'blk.2.ffn_norm.weight_type', 'blk.2.attn_k.weight', 'blk.2.attn_k.weight_type', 'blk.2.attn_output.weight', 'blk.2.attn_output.weight_type', 'blk.2.attn_q.weight', 'blk.2.attn_q.weight_type', 'blk.2.attn_v.weight', 'blk.2.attn_v.weight_type', 'blk.3.attn_norm.weight', 'blk.3.attn_norm.weight_type', 'blk.3.ffn_down.weight', 'blk.3.ffn_down.weight_type', 'blk.3.ffn_gate.weight', 'blk.3.ffn_gate.weight_type', 'blk.3.ffn_up.weight', 'blk.3.ffn_up.weight_type', 'blk.3.ffn_norm.weight', 'blk.3.ffn_norm.weight_type', 'blk.3.attn_k.weight', 'blk.3.attn_k.weight_type', 'blk.3.attn_output.weight', 'blk.3.attn_output.weight_type', 'blk.3.attn_q.weight', 'blk.3.attn_q.weight_type', 'blk.3.attn_v.weight', 'blk.3.attn_v.weight_type', 'blk.4.attn_norm.weight', 'blk.4.attn_norm.weight_type', 'blk.4.ffn_down.weight', 'blk.4.ffn_down.weight_type', 'blk.4.ffn_gate.weight', 'blk.4.ffn_gate.weight_type', 'blk.4.ffn_up.weight', 'blk.4.ffn_up.weight_type', 'blk.4.ffn_norm.weight', 'blk.4.ffn_norm.weight_type', 'blk.4.attn_k.weight', 'blk.4.attn_k.weight_type', 'blk.4.attn_output.weight', 'blk.4.attn_output.weight_type', 'blk.4.attn_q.weight', 'blk.4.attn_q.weight_type', 'blk.4.attn_v.weight', 'blk.4.attn_v.weight_type', 'blk.5.attn_norm.weight', 'blk.5.attn_norm.weight_type', 'blk.5.ffn_down.weight', 'blk.5.ffn_down.weight_type', 'blk.5.ffn_gate.weight', 'blk.5.ffn_gate.weight_type', 'blk.5.ffn_up.weight', 'blk.5.ffn_up.weight_type', 'blk.5.ffn_norm.weight', 'blk.5.ffn_norm.weight_type', 'blk.5.attn_k.weight', 'blk.5.attn_k.weight_type', 'blk.5.attn_output.weight', 'blk.5.attn_output.weight_type', 'blk.5.attn_q.weight', 'blk.5.attn_q.weight_type', 'blk.5.attn_v.weight', 'blk.5.attn_v.weight_type', 'blk.6.attn_norm.weight', 'blk.6.attn_norm.weight_type', 'blk.6.ffn_down.weight', 'blk.6.ffn_down.weight_type', 'blk.6.ffn_gate.weight', 'blk.6.ffn_gate.weight_type', 'blk.6.ffn_up.weight', 'blk.6.ffn_up.weight_type', 'blk.6.ffn_norm.weight', 'blk.6.ffn_norm.weight_type', 'blk.6.attn_k.weight', 'blk.6.attn_k.weight_type', 'blk.6.attn_output.weight', 'blk.6.attn_output.weight_type', 'blk.6.attn_q.weight', 'blk.6.attn_q.weight_type', 'blk.6.attn_v.weight', 'blk.6.attn_v.weight_type', 'blk.7.attn_norm.weight', 'blk.7.attn_norm.weight_type', 'blk.7.ffn_down.weight', 'blk.7.ffn_down.weight_type', 'blk.7.ffn_gate.weight', 'blk.7.ffn_gate.weight_type', 'blk.7.ffn_up.weight', 'blk.7.ffn_up.weight_type', 'blk.7.ffn_norm.weight', 'blk.7.ffn_norm.weight_type', 'blk.7.attn_k.weight', 'blk.7.attn_k.weight_type', 'blk.7.attn_output.weight', 'blk.7.attn_output.weight_type', 'blk.7.attn_q.weight', 'blk.7.attn_q.weight_type', 'blk.7.attn_v.weight', 'blk.7.attn_v.weight_type', 'blk.8.attn_norm.weight', 'blk.8.attn_norm.weight_type', 'blk.8.ffn_down.weight', 'blk.8.ffn_down.weight_type', 'blk.8.ffn_gate.weight', 'blk.8.ffn_gate.weight_type', 'blk.8.ffn_up.weight', 'blk.8.ffn_up.weight_type', 'blk.8.ffn_norm.weight', 'blk.8.ffn_norm.weight_type', 'blk.8.attn_k.weight', 'blk.8.attn_k.weight_type', 'blk.8.attn_output.weight', 'blk.8.attn_output.weight_type', 'blk.8.attn_q.weight', 'blk.8.attn_q.weight_type', 'blk.8.attn_v.weight', 'blk.8.attn_v.weight_type', 'blk.9.attn_norm.weight', 'blk.9.attn_norm.weight_type', 'blk.9.ffn_down.weight', 'blk.9.ffn_down.weight_type', 'blk.9.ffn_gate.weight', 'blk.9.ffn_gate.weight_type', 'blk.9.ffn_up.weight', 'blk.9.ffn_up.weight_type', 'blk.9.ffn_norm.weight', 'blk.9.ffn_norm.weight_type', 'blk.9.attn_k.weight', 'blk.9.attn_k.weight_type', 'blk.9.attn_output.weight', 'blk.9.attn_output.weight_type', 'blk.9.attn_q.weight', 'blk.9.attn_q.weight_type', 'blk.9.attn_v.weight', 'blk.9.attn_v.weight_type', 'blk.10.attn_norm.weight', 'blk.10.attn_norm.weight_type', 'blk.10.ffn_down.weight', 'blk.10.ffn_down.weight_type', 'blk.10.ffn_norm.weight', 'blk.10.ffn_norm.weight_type', 'blk.11.attn_norm.weight', 'blk.11.attn_norm.weight_type', 'blk.11.ffn_down.weight', 'blk.11.ffn_down.weight_type', 'blk.11.ffn_gate.weight', 'blk.11.ffn_gate.weight_type', 'blk.11.ffn_up.weight', 'blk.11.ffn_up.weight_type', 'blk.11.ffn_norm.weight', 'blk.11.ffn_norm.weight_type', 'blk.11.attn_k.weight', 'blk.11.attn_k.weight_type', 'blk.11.attn_output.weight', 'blk.11.attn_output.weight_type', 'blk.11.attn_q.weight', 'blk.11.attn_q.weight_type', 'blk.11.attn_v.weight', 'blk.11.attn_v.weight_type', 'blk.12.attn_norm.weight', 'blk.12.attn_norm.weight_type', 'blk.12.ffn_down.weight', 'blk.12.ffn_down.weight_type', 'blk.12.ffn_gate.weight', 'blk.12.ffn_gate.weight_type', 'blk.12.ffn_up.weight', 'blk.12.ffn_up.weight_type', 'blk.12.ffn_norm.weight', 'blk.12.ffn_norm.weight_type', 'blk.12.attn_k.weight', 'blk.12.attn_k.weight_type', 'blk.12.attn_output.weight', 'blk.12.attn_output.weight_type', 'blk.12.attn_q.weight', 'blk.12.attn_q.weight_type', 'blk.12.attn_v.weight', 'blk.12.attn_v.weight_type', 'blk.13.attn_norm.weight', 'blk.13.attn_norm.weight_type', 'blk.13.ffn_down.weight', 'blk.13.ffn_down.weight_type', 'blk.13.ffn_gate.weight', 'blk.13.ffn_gate.weight_type', 'blk.13.ffn_up.weight', 'blk.13.ffn_up.weight_type', 'blk.13.ffn_norm.weight', 'blk.13.ffn_norm.weight_type', 'blk.13.attn_k.weight', 'blk.13.attn_k.weight_type', 'blk.13.attn_output.weight', 'blk.13.attn_output.weight_type', 'blk.13.attn_q.weight', 'blk.13.attn_q.weight_type', 'blk.13.attn_v.weight', 'blk.13.attn_v.weight_type', 'blk.14.attn_norm.weight', 'blk.14.attn_norm.weight_type', 'blk.14.ffn_down.weight', 'blk.14.ffn_down.weight_type', 'blk.14.ffn_gate.weight', 'blk.14.ffn_gate.weight_type', 'blk.14.ffn_up.weight', 'blk.14.ffn_up.weight_type', 'blk.14.ffn_norm.weight', 'blk.14.ffn_norm.weight_type', 'blk.14.attn_k.weight', 'blk.14.attn_k.weight_type', 'blk.14.attn_output.weight', 'blk.14.attn_output.weight_type', 'blk.14.attn_q.weight', 'blk.14.attn_q.weight_type', 'blk.14.attn_v.weight', 'blk.14.attn_v.weight_type', 'blk.15.attn_norm.weight', 'blk.15.attn_norm.weight_type', 'blk.15.ffn_down.weight', 'blk.15.ffn_down.weight_type', 'blk.15.ffn_gate.weight', 'blk.15.ffn_gate.weight_type', 'blk.15.ffn_up.weight', 'blk.15.ffn_up.weight_type', 'blk.15.ffn_norm.weight', 'blk.15.ffn_norm.weight_type', 'blk.15.attn_k.weight', 'blk.15.attn_k.weight_type', 'blk.15.attn_output.weight', 'blk.15.attn_output.weight_type', 'blk.15.attn_q.weight', 'blk.15.attn_q.weight_type', 'blk.15.attn_v.weight', 'blk.15.attn_v.weight_type', 'blk.16.attn_norm.weight', 'blk.16.attn_norm.weight_type', 'blk.16.ffn_down.weight', 'blk.16.ffn_down.weight_type', 'blk.16.ffn_gate.weight', 'blk.16.ffn_gate.weight_type', 'blk.16.ffn_up.weight', 'blk.16.ffn_up.weight_type', 'blk.16.ffn_norm.weight', 'blk.16.ffn_norm.weight_type', 'blk.16.attn_k.weight', 'blk.16.attn_k.weight_type', 'blk.16.attn_output.weight', 'blk.16.attn_output.weight_type', 'blk.16.attn_q.weight', 'blk.16.attn_q.weight_type', 'blk.16.attn_v.weight', 'blk.16.attn_v.weight_type', 'blk.17.attn_norm.weight', 'blk.17.attn_norm.weight_type', 'blk.17.ffn_down.weight', 'blk.17.ffn_down.weight_type', 'blk.17.ffn_gate.weight', 'blk.17.ffn_gate.weight_type', 'blk.17.ffn_up.weight', 'blk.17.ffn_up.weight_type', 'blk.17.ffn_norm.weight', 'blk.17.ffn_norm.weight_type', 'blk.17.attn_k.weight', 'blk.17.attn_k.weight_type', 'blk.17.attn_output.weight', 'blk.17.attn_output.weight_type', 'blk.17.attn_q.weight', 'blk.17.attn_q.weight_type', 'blk.17.attn_v.weight', 'blk.17.attn_v.weight_type', 'blk.18.attn_norm.weight', 'blk.18.attn_norm.weight_type', 'blk.18.ffn_down.weight', 'blk.18.ffn_down.weight_type', 'blk.18.ffn_gate.weight', 'blk.18.ffn_gate.weight_type', 'blk.18.ffn_up.weight', 'blk.18.ffn_up.weight_type', 'blk.18.ffn_norm.weight', 'blk.18.ffn_norm.weight_type', 'blk.18.attn_k.weight', 'blk.18.attn_k.weight_type', 'blk.18.attn_output.weight', 'blk.18.attn_output.weight_type', 'blk.18.attn_q.weight', 'blk.18.attn_q.weight_type', 'blk.18.attn_v.weight', 'blk.18.attn_v.weight_type', 'blk.19.attn_norm.weight', 'blk.19.attn_norm.weight_type', 'blk.19.ffn_down.weight', 'blk.19.ffn_down.weight_type', 'blk.19.ffn_gate.weight', 'blk.19.ffn_gate.weight_type', 'blk.19.ffn_up.weight', 'blk.19.ffn_up.weight_type', 'blk.19.ffn_norm.weight', 'blk.19.ffn_norm.weight_type', 'blk.19.attn_k.weight', 'blk.19.attn_k.weight_type', 'blk.19.attn_output.weight', 'blk.19.attn_output.weight_type', 'blk.19.attn_q.weight', 'blk.19.attn_q.weight_type', 'blk.19.attn_v.weight', 'blk.19.attn_v.weight_type', 'blk.20.attn_norm.weight', 'blk.20.attn_norm.weight_type', 'blk.20.ffn_down.weight', 'blk.20.ffn_down.weight_type', 'blk.20.ffn_gate.weight', 'blk.20.ffn_gate.weight_type', 'blk.20.ffn_up.weight', 'blk.20.ffn_up.weight_type', 'blk.20.ffn_norm.weight', 'blk.20.ffn_norm.weight_type', 'blk.20.attn_k.weight', 'blk.20.attn_k.weight_type', 'blk.20.attn_output.weight', 'blk.20.attn_output.weight_type', 'blk.20.attn_q.weight', 'blk.20.attn_q.weight_type', 'blk.20.attn_v.weight', 'blk.20.attn_v.weight_type', 'blk.21.attn_norm.weight', 'blk.21.attn_norm.weight_type', 'blk.21.ffn_down.weight', 'blk.21.ffn_down.weight_type', 'blk.21.ffn_gate.weight', 'blk.21.ffn_gate.weight_type', 'blk.21.ffn_up.weight', 'blk.21.ffn_up.weight_type', 'blk.21.ffn_norm.weight', 'blk.21.ffn_norm.weight_type', 'blk.21.attn_k.weight', 'blk.21.attn_k.weight_type', 'blk.21.attn_output.weight', 'blk.21.attn_output.weight_type', 'blk.21.attn_q.weight', 'blk.21.attn_q.weight_type', 'blk.21.attn_v.weight', 'blk.21.attn_v.weight_type', 'blk.22.attn_k.weight', 'blk.22.attn_k.weight_type', 'blk.22.attn_output.weight', 'blk.22.attn_output.weight_type', 'blk.22.attn_q.weight', 'blk.22.attn_q.weight_type', 'blk.22.attn_v.weight', 'blk.22.attn_v.weight_type', 'output.weight', 'output.weight_type', 'blk.22.attn_norm.weight', 'blk.22.attn_norm.weight_type', 'blk.22.ffn_down.weight', 'blk.22.ffn_down.weight_type', 'blk.22.ffn_gate.weight', 'blk.22.ffn_gate.weight_type', 'blk.22.ffn_up.weight', 'blk.22.ffn_up.weight_type', 'blk.22.ffn_norm.weight', 'blk.22.ffn_norm.weight_type', 'blk.23.attn_norm.weight', 'blk.23.attn_norm.weight_type', 'blk.23.ffn_down.weight', 'blk.23.ffn_down.weight_type', 'blk.23.ffn_gate.weight', 'blk.23.ffn_gate.weight_type', 'blk.23.ffn_up.weight', 'blk.23.ffn_up.weight_type', 'blk.23.ffn_norm.weight', 'blk.23.ffn_norm.weight_type', 'blk.23.attn_k.weight', 'blk.23.attn_k.weight_type', 'blk.23.attn_output.weight', 'blk.23.attn_output.weight_type', 'blk.23.attn_q.weight', 'blk.23.attn_q.weight_type', 'blk.23.attn_v.weight', 'blk.23.attn_v.weight_type', 'blk.24.attn_norm.weight', 'blk.24.attn_norm.weight_type', 'blk.24.ffn_down.weight', 'blk.24.ffn_down.weight_type', 'blk.24.ffn_gate.weight', 'blk.24.ffn_gate.weight_type', 'blk.24.ffn_up.weight', 'blk.24.ffn_up.weight_type', 'blk.24.ffn_norm.weight', 'blk.24.ffn_norm.weight_type', 'blk.24.attn_k.weight', 'blk.24.attn_k.weight_type', 'blk.24.attn_output.weight', 'blk.24.attn_output.weight_type', 'blk.24.attn_q.weight', 'blk.24.attn_q.weight_type', 'blk.24.attn_v.weight', 'blk.24.attn_v.weight_type', 'blk.25.attn_norm.weight', 'blk.25.attn_norm.weight_type', 'blk.25.ffn_down.weight', 'blk.25.ffn_down.weight_type', 'blk.25.ffn_gate.weight', 'blk.25.ffn_gate.weight_type', 'blk.25.ffn_up.weight', 'blk.25.ffn_up.weight_type', 'blk.25.ffn_norm.weight', 'blk.25.ffn_norm.weight_type', 'blk.25.attn_k.weight', 'blk.25.attn_k.weight_type', 'blk.25.attn_output.weight', 'blk.25.attn_output.weight_type', 'blk.25.attn_q.weight', 'blk.25.attn_q.weight_type', 'blk.25.attn_v.weight', 'blk.25.attn_v.weight_type', 'blk.26.attn_norm.weight', 'blk.26.attn_norm.weight_type', 'blk.26.ffn_down.weight', 'blk.26.ffn_down.weight_type', 'blk.26.ffn_gate.weight', 'blk.26.ffn_gate.weight_type', 'blk.26.ffn_up.weight', 'blk.26.ffn_up.weight_type', 'blk.26.ffn_norm.weight', 'blk.26.ffn_norm.weight_type', 'blk.26.attn_k.weight', 'blk.26.attn_k.weight_type', 'blk.26.attn_output.weight', 'blk.26.attn_output.weight_type', 'blk.26.attn_q.weight', 'blk.26.attn_q.weight_type', 'blk.26.attn_v.weight', 'blk.26.attn_v.weight_type', 'blk.27.attn_norm.weight', 'blk.27.attn_norm.weight_type', 'blk.27.ffn_down.weight', 'blk.27.ffn_down.weight_type', 'blk.27.ffn_gate.weight', 'blk.27.ffn_gate.weight_type', 'blk.27.ffn_up.weight', 'blk.27.ffn_up.weight_type', 'blk.27.ffn_norm.weight', 'blk.27.ffn_norm.weight_type', 'blk.27.attn_k.weight', 'blk.27.attn_k.weight_type', 'blk.27.attn_output.weight', 'blk.27.attn_output.weight_type', 'blk.27.attn_q.weight', 'blk.27.attn_q.weight_type', 'blk.27.attn_v.weight', 'blk.27.attn_v.weight_type', 'blk.28.attn_norm.weight', 'blk.28.attn_norm.weight_type', 'blk.28.ffn_down.weight', 'blk.28.ffn_down.weight_type', 'blk.28.ffn_gate.weight', 'blk.28.ffn_gate.weight_type', 'blk.28.ffn_up.weight', 'blk.28.ffn_up.weight_type', 'blk.28.ffn_norm.weight', 'blk.28.ffn_norm.weight_type', 'blk.28.attn_k.weight', 'blk.28.attn_k.weight_type', 'blk.28.attn_output.weight', 'blk.28.attn_output.weight_type', 'blk.28.attn_q.weight', 'blk.28.attn_q.weight_type', 'blk.28.attn_v.weight', 'blk.28.attn_v.weight_type', 'blk.29.attn_norm.weight', 'blk.29.attn_norm.weight_type', 'blk.29.ffn_down.weight', 'blk.29.ffn_down.weight_type', 'blk.29.ffn_gate.weight', 'blk.29.ffn_gate.weight_type', 'blk.29.ffn_up.weight', 'blk.29.ffn_up.weight_type', 'blk.29.ffn_norm.weight', 'blk.29.ffn_norm.weight_type', 'blk.29.attn_k.weight', 'blk.29.attn_k.weight_type', 'blk.29.attn_output.weight', 'blk.29.attn_output.weight_type', 'blk.29.attn_q.weight', 'blk.29.attn_q.weight_type', 'blk.29.attn_v.weight', 'blk.29.attn_v.weight_type', 'blk.30.attn_norm.weight', 'blk.30.attn_norm.weight_type', 'blk.30.ffn_down.weight', 'blk.30.ffn_down.weight_type', 'blk.30.ffn_gate.weight', 'blk.30.ffn_gate.weight_type', 'blk.30.ffn_up.weight', 'blk.30.ffn_up.weight_type', 'blk.30.ffn_norm.weight', 'blk.30.ffn_norm.weight_type', 'blk.30.attn_k.weight', 'blk.30.attn_k.weight_type', 'blk.30.attn_output.weight', 'blk.30.attn_output.weight_type', 'blk.30.attn_q.weight', 'blk.30.attn_q.weight_type', 'blk.30.attn_v.weight', 'blk.30.attn_v.weight_type', 'blk.31.attn_norm.weight', 'blk.31.attn_norm.weight_type', 'blk.31.ffn_down.weight', 'blk.31.ffn_down.weight_type', 'blk.31.ffn_gate.weight', 'blk.31.ffn_gate.weight_type', 'blk.31.ffn_up.weight', 'blk.31.ffn_up.weight_type', 'blk.31.ffn_norm.weight', 'blk.31.ffn_norm.weight_type', 'blk.31.attn_k.weight', 'blk.31.attn_k.weight_type', 'blk.31.attn_output.weight', 'blk.31.attn_output.weight_type', 'blk.31.attn_q.weight', 'blk.31.attn_q.weight_type', 'blk.31.attn_v.weight', 'blk.31.attn_v.weight_type', 'output_norm.weight', 'output_norm.weight_type'])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T08:59:22.961273Z",
     "start_time": "2024-03-01T08:59:22.958025Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\r\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\r\n",
      "Installing collected packages: torchsummary\r\n",
      "Successfully installed torchsummary-1.5.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T08:55:23.397838Z",
     "start_time": "2024-03-01T08:55:21.508167Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Caches must be initialized first",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchsummary\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m torchsummary\n\u001B[0;32m----> 3\u001B[0m \u001B[43mtorchsummary\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msummary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/torchsummary/torchsummary.py:72\u001B[0m, in \u001B[0;36msummary\u001B[0;34m(model, input_size, batch_size, device)\u001B[0m\n\u001B[1;32m     68\u001B[0m model\u001B[38;5;241m.\u001B[39mapply(register_hook)\n\u001B[1;32m     70\u001B[0m \u001B[38;5;66;03m# make a forward pass\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# print(x.shape)\u001B[39;00m\n\u001B[0;32m---> 72\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# remove these hooks\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m h \u001B[38;5;129;01min\u001B[39;00m hooks:\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/simulationllm/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/UCU/ua-gec-lora/src/packages/training/model_utils.py:93\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[0;34m(self, idx, input_pos)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx: Tensor, input_pos: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m---> 93\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfreqs_cis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCaches must be initialized first\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     94\u001B[0m     mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcausal_mask[\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, input_pos]\n\u001B[1;32m     95\u001B[0m     freqs_cis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfreqs_cis[input_pos]\n",
      "\u001B[0;31mAssertionError\u001B[0m: Caches must be initialized first"
     ]
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T08:55:47.867148Z",
     "start_time": "2024-03-01T08:55:47.770879Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
